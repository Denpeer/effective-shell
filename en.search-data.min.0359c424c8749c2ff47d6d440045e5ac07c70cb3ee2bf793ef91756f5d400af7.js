'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/section6/the-future/','title':"The Future",'content':""});index.add({'id':1,'href':'/docs/1-getting-started/','title':"Chapter 1 - Getting Started",'content':"Chapter 1 - Getting Started This section is for those who are completely new to this topic. In this section we'll introduce just what the shell is, who this book is useful for, and what you can expect to learn.\nWe'll also look at how to set your computer up so that you can follow along with the examples. We'll finish by demonstrating a few basic skills so that you can learn to move around in the shell and get started with the rest of the book.\nIf you are already comfortable with running a shell, know what Bash is, and know how to run basic commands like ls and cd, then you can completely skip this section.\nIf you are already comfortable with running a shell, know what bash is, and know how to run basic commands like ls and cd, are familiar with terms like command and parameter then you can skip this section. You could also just review the Summary to make sure that you are comfortable with the material which has been introduced and then move onto the next section.\nWhat is the Shell? If you don't know what the shell is, then this is the place to start!\nWhen we talk about \u0026ldquo;The Shell\u0026rdquo;, we're normally referring to the simple, text-based interface which is used to control a computer or a program.\nHere's what the shell looks like on Windows:\nAnd here's what it looks like on a Mac:\nAnd here's what it looks like on Fedora, a popular Linux distribution:\nWhen we are talking about the shell in this book, we're talking about the simple program which can be used to operate the computer using this text based interface.\nWhy would you want to do this? There are a few reasons!\nFirstly, using the shell can help you learn more about the internals of how your computer can work. This can be really helpful if you are technology professional or work with computers.\nSecondly, there are some scenarios where you have to use a shell. Not every program or system can be operated with a Graphical User Interface, which is the visual point-and-click interface you are probably using now. Some lower-level programs do not have such interfaces, and many computers do not either.\nFinally, there are some scenarios where it can be more efficient to use the shell. Operations which might be time consuming or repetitive to perform using the user interface might be much faster to perform in a shell. You can also write shell scripts to automate these kinds of operations.\nIn the next section you'll learn how to startup the shell on your computer. Once this is done you are ready to continue with the book.\nOpening the Shell Now let's actually learn how to open the shell on your computer.\nOnce we've done this, we might need to make some configuration changes so that we get it to behave in a way which as consistent with other shells as possible - we'll get to that in the next chapter.\nMicrosoft Windows There are a number of shell programs on Microsoft Windows. We'll be using the basic shell which is pre-installed, which is called the \u0026ldquo;Command Prompt\u0026rdquo;.\nTo open the command prompt, start by clicking the start button on the bottom left hand side of the screen, and type command prompt. Open the Command Prompt program:\nOnce the program has opened, type whoami then hit the Return key. The whoami program will show the username of the logged in user:\nThat's it! We've still got some configuration to do to make this shell behave more like a Linux shell, which this book uses as the standard, but we'll come to that in the next section.\nMacOS If you are using a Mac, then you just need to run the \u0026ldquo;Terminal\u0026rdquo; program to open your shell. Hold down the Command Key and press Space, then type terminal. Open the terminal program which is shown:\nOnce the program has opened, type whoami then hit the Return key. The whoami program will show the username of the logged in user:\nThat's it! In the next section we'll make some minor configuration changes to keep things consistent with the samples in the book.\nLinux / Unix If you are using a Linux or Unix system, I'll assume that you are familiar enough with it to open a shell. Which terminal you use should not affect how you use this book, but for consistencies sake be aware that most of the examples are assuming that the user is using Bash version 5.\nConfiguring the Shell Shells can vary enormously between different systems. In general, Linux systems tend to use the \u0026ldquo;Bash\u0026rdquo; shell and require little configuration. Apple's MacOS operating system is actually based on BSD Unix, and under the hood is somewhat different to most Linux systems. Microsoft Windows is a completely unrelated operating system to either Linux or Unix and operates in a fundamentally different way both of them.\nIn this book, we assume that you are using a \u0026ldquo;Linux-like\u0026rdquo; system, something which operates like a modern Linux distribution. This is a deliberate choice. If you become comfortable using a Linux-like shell, you can generally apply the techniques we'll show to MacOS with no difficulties. For Windows, the techniques are not necessarily transferable immediately, but still valuable to know. Windows is actually being updated at the time of writing to provide a Linux-like shell interface as part of the core operating system (this is known as the Windows Subsystem Linux. As time progresses it will be easier to run commands using the techniques in this book natively, but for now we'll have to tweak a few things.\nIn this section we'll make sure that we are running with a setup which is close to Linux, and aim to set the latest version of our shell to the popular \u0026ldquo;Bash\u0026rdquo; program. If you are familiar with Bash but prefer to use another shell, that is fine, most of the book will work with any modern shell. However, if you are not sure what shell you should be using, I would recommend you follow the guides below to setup the most popular shell at its latest version.\nOnce this is done then we are ready to get into the book properly!\nMicrosoft Windows Windows is not anything like Linux under the hood. So to get a shell working, we have three options:\n Use a tool which provides common Linux tools which have been written to work with Windows Use a \u0026ldquo;virtual machine\u0026rdquo; running Linux Use the Windows Subsystem for Linux  The first option is the best if you want to actually be able to work with the files on your computer quickly and easily day to day.\nThe second option is best if you want to be able to experiment with the shell, but keep it completely separate from your main computer and its files.\nThe final option is best if you are a power user or expert who wants to use the latest WSL features and build the skills with the platform as soon as possible.\nWe'll go through all options here.\nOption 1: Install Linux Tools This is probably the easiest option and the one I would recommend for most user. It will let you run something like a Linux shell when you choose to, but not get in your way during day-to-day usage of your computer.\nTo get a Linux-like experience on a Windows machine, we'll install Cygwin. Cygwin provides a large set of programs which are generally available on Linux systems, which are designed to work on Windows.\nDownload the Cygwin installer and start the installation process. You should see something like this:\nStart the installation and tell it to install from the internet (the default option):\nInstall for all users in the default location. It is also fine to change the options if you prefer:\nCygwin will ask you where to install downloaded packages, whether a proxy is needed, and what download sites to use. Leave these options at their default unless you know what you are doing and why you'd need to change them. It will then start downloading. Once it has downloaded the list of available packages to install, it will ask which packages you want. Choose the default option \u0026ldquo;All\u0026rdquo;:\nThe installer will now start downloading and installing the programs:\nOnce Cygwin has finished installing, you will have a link to open Cygwin available on the desktop and start menu.\nYou can use this link to start using the \u0026ldquo;Bash\u0026rdquo; shell, or if you prefer you can open the \u0026ldquo;Command Prompt\u0026rdquo; as described in Opening the Shell and run the bash program:\nNote that you shouldn't use the --norc option. I have used it in the screenshot above just so that my Bash looks like it would after a clean install, without my own customisations added.\nAt this point you have a ready-to-go bash environment and can continue on to the Summary and Next Section.\nOption 2: Use a Virtual Machine We can run a virtual machine on Windows which will give us a complete Linux environment. This is an ideal way to create a safe sandbox for experimentation, without changing how the rest of the system is setup.\nThere are many ways to run a virtual machine on Windows. For this example we'll use the free \u0026lsquo;Oracle VirtualBox\u0026rsquo; tool. VirtualBox will run a virtual machine, and on that virtual machine we will install the popular Ubuntu distribution of Linux.\nFirst, start downloading Ubuntu, which might take some time as the download is quite large. You will want to install the latest Desktop Edition (which at the time of writing is version 18):\nWhile the Ubuntu software downloads, we can install VirtualBox. Go to the VirtualBox Website and download the VirtualBox installer. You will need the installer for \u0026lsquo;Windows Hosts\u0026rsquo;.\nOnce the installer has downloaded, run it to start the installation:\nNext you will be asked to configure the installation options. The defaults will be fine for most users:\nThen the installation will start:\nOnce the installation is complete and the Ubuntu installer has downloaded we can move onto the next step.\nOpen VirtualBox and choose \u0026lsquo;New\u0026rsquo; to create a new Virtual Machine. Ensure \u0026ldquo;Expert Mode\u0026rdquo; is selected. Provide a name for the machine and choose \u0026ldquo;Linux\u0026rdquo; as the type and \u0026ldquo;Ubuntu_64\u0026rdquo; as the version type. Everything else can be left as the default, unless you want to tweak the machine settings:\nYou will be asked to setup a virtual hard disk. I would recommend the default options for most users:\nOnce the machine has been created it will be shown in the main VirtualBox window. Select the machine and choose \u0026ldquo;Start\u0026rdquo;:\nWhen the machine starts up it will ask you for a \u0026ldquo;Startup Disk\u0026rdquo;. This is the disk which will be used to setup the operating system. Press the \u0026ldquo;browse\u0026rdquo; icon, then choose \u0026ldquo;open\u0026rdquo; and select the Ubuntu file which you downloaded, which should end in .iso:\nIf this step fails, you may need to disable \u0026ldquo;Hyper-V\u0026rdquo; and \u0026ldquo;Windows Sandbox\u0026rdquo; by going to \u0026ldquo;Add or Remove Windows features\u0026rdquo;:\nAfter a short while you will see the Ubuntu installer start up. Choose the \u0026ldquo;Install Ubuntu\u0026rdquo; option:\nYou can specify language settings, what components are installed and more. These options can be left at the default. On the final page, choose the \u0026ldquo;Erase disk and install Ubuntu\u0026rdquo; option:\nThe final step will be to choose a name for the computer, and a username and password to log in with. You can use any values you like here, just don't forget them!\nAfter this the installation will proceed. It might take a little while. After the installation is complete, you will need to restart. If you get an error saying \u0026ldquo;Please remove installation medium\u0026rdquo; just power off the machine and restart it. After restarting you can log into the machine with the credentials you specified earlier.\nWhen you have logged in, press the applications icon on the bottom-left of the screen and search for the \u0026ldquo;Terminal\u0026rdquo; application:\nYou are now running the \u0026ldquo;Bash\u0026rdquo; shell in the terminal. You can run the whoami command to show the current user, or bash --version to see the version of Bash which is installed:\nThat's it! You now have a virtual machine running Ubuntu and Bash which you can use to learn about the shell.\nOption 3: Setup the Windows Subsystem for Linux The Windows Subsystem for Linux is a relatively new set of features for Microsoft Windows. It allows users to install a Linux distribution on their Windows machine. This is a great way for us to be able to use the \u0026ldquo;Bash\u0026rdquo; shell without having to set up a virtual machine.\nFirst, open up the \u0026ldquo;Turn Windows Features on or off\u0026rdquo; option from the control panel:\nThen enable the \u0026ldquo;Windows Subsystem for Linux\u0026rdquo; feature:\nAfter your computer has restarted, open up the Windows App Store and search for \u0026ldquo;Ubuntu\u0026rdquo;:\nOnce Ubuntu has installed, open up the app. It will then initialise (which can take a little while):\nChoose a username and password to complete the setup:\nAnd that's it! You can now open the Ubuntu app at any time to use Ubuntu on Windows, interfacing using the Bash shell.\nMacOS If you are running a Mac, then you can probably run the standard Terminal program and follow the material in this book without making any changes. However, the version of Bash which comes installed by default on MacOS is version 3, which is a little out of date. I would strongly suggest that you upgrade the default installation. On MacOS Catalina, the default shell has changed to Z Shell - this should work fine for all of the examples in this book, but you might want to switch it to Bash to be on the safe side (you can always change back later).\nTo install the right software, we'll use a tool called Homebrew. Homebrew is a \u0026lsquo;package manager\u0026rsquo;, a tool used to install software on your computer, from the shell. It's kind of like the App Store but for shell users!\nFirst, follow the instructions online to install Homebrew:\nIn most cases, this will require opening the terminal programming and running a snippet which looks like this:\n/usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; However, this might have changed since the time of writing so do check the website to see what the latest instructions are. You don't actually need to know what is going on with this command (but by the time you've worked through a bit more of this book it will make sense!), but in a nutshell it runs a basic installation script, using the Ruby programming language (which comes pre-installed on MacOS).\nOnce this has installed, install Bash by running the following command in the shell:\nbrew install bash This uses the brew command, which we have just installed, to install the bash program.\nFinally, update the Terminal preferences to use the version of Bash you have just installed, rather than the default, by setting the shell location to /usr/local/bin/bash:\nAgain, why we make these changes is not essential to know for now, we'll go into more details in a later section. Once you've made this change, whenever you open a new terminal window, it will run the latest version of Bash, which you can confirm by running echo $BASH_VERSION:\nThere is actually a more sophisticated way to change what shell is used in a system, which is the special chsh command (short for \u0026ldquo;change shell\u0026rdquo;). We'll see this in a later section. We'll also see what echo is in more detail shortly.\nLinux As before, if you are running Linux I will assume you are able to open a terminal and setup the appropriate shell. You can follow along with the content in this book with any recent Bash-like shell.\nThat's It! Later on we'll see a little more about the differences between different shell programs, what the difference between a shell and a terminal is and more. But for now, you are ready to go and move onto the Summary and then Section 1.\nA Quick Demo of the Shell If you have never used the shell before, then this is where we'll start. We're not going to go into lots of detail, there's plenty of that later on in book. Instead we'll do a quick crash course on the basics. If you have not used the shell before this'll give you a chance to see how it works.\nStart by opening your shell. This is covered in Opening the Shell. Your shell should be Bash - if this doesn't sound familiar, then make sure you have followed the instructions in Configuring the Shell.\nYou should see your terminal program running your shell. You can see what the version is of your shell by running:\nbash --version Let's quickly dissect this. We have run the bash command. A command can be a program on your computer, or it can be something built into the shell. We'll look at this in a lot more detail later, but for now it's important to understand that a lot of what you will be doing is running commands.\nThe --version text is a parameter. Parameters affect how commands work. This is actually easier to see with an example.\nLet's move to the home folder. On most computers your home folder is your personal space where things like documents, photos, music, downloads and so on are kept.\nLet's switch to the home folder by running the following command:\ncd ~ Once you've done that, run the pwd command:\npwd So what has happened here? The first command:\ncd ~ Is used to change directory - that's what cd stands for. The parameter we passed to cd was just the \u0026lsquo;tilde\u0026rsquo; character (~). This character has a special meaning in the shell - it means \u0026ldquo;the current user's home directory\u0026rdquo;.\nFinally, we ran the pwd command. This command is short for print working directory. It writes out to the screen where you currently are. On my Mac, my home directory is located at /Users/dwmkerr, which is what the command has shown me.\nLet's take another look at a command. Run the following in your shell:\nls The ls command is short for list directory contents - it shows you everything that is in the current directory. On my computer you can see things like the \u0026lsquo;Downloads\u0026rsquo;, \u0026lsquo;Music\u0026rsquo; and \u0026lsquo;Pictures\u0026rsquo; folders, which are set up by default on a Mac, as well as some of my own folders.\nWe can pass different parameters to ls. The main parameter is the location of the folder we'd like to list the contents of. So if we wanted to see what was in the Music folder, we'd just run:\nls Music Not much to see here:\nMany commands actually allow us to pass multiple parameters. For example, we could list the contents of my Movies and my personal applications:\nls Movies Applications There's not much in either. You might wonder why Applications is so empty - that's because we're looking at the applications only installed for the current user, because we are in the user's home directory. To see the applications for everyone we'd need to use the folder where applications are kept for all users.\nWe can do this by running ls /Appliciations:\nThe trick here is that we start with a leading forward slash - this means the Applications folder in the root of the computer, not the one in my current folder.\nOn Windows, applications are kept in different places, but we can see some of the installed applications by running ls \u0026quot;c:\\program files\\\u0026quot;:\nWhy do we have the extra quotation marks here? If we ran the command without the quotation marks, the shell would think we were giving it two parameters. It would think we wanted to see the contents of the c:\\program and files folders - and they don't exist!\nThe error above shows what happens when we miss the quotation marks.\nNow we can take a look at how a flag would work. A flag is a parameter which changes how a command works. Flags normally start with a hyphen. Let's say we wanted to know the size of the files in the folder. We do this by using the -lh pass the parameter, which is short for long list, human readable:\nls -lh Downloads/*.jpg Now I can see all of the jpg files (jpg files are images) in my Downloads folder. I can see it looks like I've got two pictures of \u0026ldquo;Mardi Himal\u0026rdquo; (a mountain in the Himalayas) which are both 384 Kilobytes in size, as well as some other images. Blow by blow, this is what we've got:\n ls - List the contents of a folder -lh - This is the long list in human-readable sizes parameter, which means we see how big the files are in a friendly format (like 911K for Kilobytes, rather than showing something like 911012 which would be the number of bytes - and harder to read!) Downloads/*.jpg - Show the contents of the Downloads folder, including any files which end with .jpg - the * is a wildcard which means that we don't mind what the filename is  The -lh parameter is shorthand. Many commands offer longhand parameters (such as --version) as well as shorthand (such as -v as an alternative for --version). Longhand is easier to read, shorthand is faster to type.\nDon't worry - in the next section we'll see how to look up the available parameters for a command. You don't need to remember all of these details, only understand which part is the command and which parts are the parameters. This is just an introduction for now!\nNow let's look at one more command.\nThe Echo Command The \u0026lsquo;echo\u0026rsquo; command is used to write out a message in the shell. Here's an example of how it works:\necho \u0026#34;Hello Shell!\u0026#34; This command writes out the text Hello Shell!:\nWhy would we do this? One of the most common reasons would be to see what the shell thinks a certain value is. For example, try this command:\necho \u0026#34;My home directory is at: $HOME\u0026#34; You'll see something like this:\nThe $HOME part of the text is called a variable. We can recognise variables because they start with a dollar symbol. $HOME is a built-in variable which holds the location of the current user's home directory.\nWe're going to see all sorts of cool things we can do with echo as we continue in the book!\nMove Around One common thing we can do in a visual file explorer is move around. We can open folders, and go \u0026lsquo;up\u0026rsquo; from the current folder. We often also see visually where we are in the folder structure with an \u0026lsquo;address bar\u0026rsquo;.\nA useful reference might be the picture below:\nHere we map the shell commands to the visual interface's equivalents:\n pwd shows the current working directory - where you currently are in the file system ls lists the files in the current directory (or any directory you tell it) cd .. changes the directory to another location - if you use the special .. directory, you are telling it to change to the parent directory, i.e. \u0026lsquo;go up\u0026rsquo; in the file system  As a final trick, lets see how we open a file or folder. Let's say I want to open one of the photos in my Downloads folder. Here's how I can do it:\ncd ~/Downloads open himalayas.jpg We can see the result here:\nRunning open himalayas.jpg has opened the photo in the application which is used for photos by default in the operating system.\nBe aware - this command is different on different operating systems (but we're going to see later on how to fix that and make it consistent everywhere!). The open command will open a file on MacOS. On Windows you can use start, and on Linux you can generally use xdg-open.\nAs a nifty trick, trying running open .1:\n. This will open the current folder. Every folder contains two \u0026lsquo;special\u0026rsquo; folders. The first is .., which we've seen means \u0026lsquo;my parent folder\u0026rsquo; and the second is ., which means \u0026lsquo;myself\u0026rsquo;. Having this . folder is convenient, as it means we can do things like this - run a command to open the current folder.\nWe're going to go into a lot more detail on how to work with files and folders, move around, but hopefully this has provided a crash course for the basics. They key concepts to remember, which are much more important than the individual commands we've see are:\n In the shell we run commands We can change how commands work by using parameters Some parameters just go at the end of the command - like ls Downloads Some parameters start with a hyphen, and change how the command behaves - these are often called \u0026lsquo;flags\u0026rsquo;. An example is ls -lh, which lists the files in the current folder with a human-readable file size  We've also learned:\n cd changes the current directory pwd prints the current directory ls lists the files in a directory echo can be used to write out text to the screen open, start and xdg-open can be used to open a file or folder on MacOS, Windows and Linux respectively  Now we can start to get into more detail!\nSummary In this section we learnt:\n That this book is for IT professionals, hobbyists or anyone who wants to learn more about how to work with computers What the shell is, and why we might want to use it How to open the shell programs for Windows, Mac and Linux which are installed by default How to configure the shells for Windows or Mac to behave in a Linux-like way to allow us to follow on with the rest of the book  We introduced the following commands:\n cd - which changes directory pwd - which prints the current working directory ls - which lists the contents of a directory echo - which writes text to the screen open - which will open a file or folder  We also briefly introduced variables, which are special values which start with the dollar symbol, such as $HOME which stores the user's home directory. We saw that each directory contains two special directories - .. which represents the parent directory, and . which represents the current directory.\nWith these tasks complete we can now move onto the next section.\n Footnotes\n  On Windows you might need to run start . and on Linux, xdg-open .. \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':2,'href':'/docs/part-1-transitioning-to-the-shell/2-navigating-your-system/','title':"Chapter 2 - Navigating Your System",'content':"Chapter 2 - Navigating Your System Switching from a graphical user interface to the shell can take some getting used to. First we'll take a look at how to navigate your system using the shell, and get information on files and folders in the system.\nThis section will introduce the pwd, ls, cd, pushd and popd commands, as well as the concepts of the \u0026ldquo;working directory\u0026rdquo; and \u0026ldquo;environment variables\u0026rdquo;. We'll also take a bit of a look into how \u0026ldquo;Paths\u0026rdquo; work.\nIf these commands far familiar to you then feel free to jump to the next chapter! Otherwise, let's get started.\nThe Working Directory Perhaps the easiest way to start to understand how to navigate your system using the shell is to use a graphical interface as an illustration of how we often navigate. Open your shell, and enter the following command:\npwd You should see something like this:\nWhen we open a folder in a graphical user interface, we are always viewing the contents of a folder, or directory. When you open the shell, the same applies - we are always sitting in a specific directory.\nThe pwd command is the Print Working Directory command. It shows the full path of the directory that you are in. You might not use this command very often, as in many shells you can see the directory you are in (if you cannot see this in your shell, you'll find out how to do this in Chapter 18).\nThere's one more way to find the working directory. It is stored in an Environment Variable called PWD.\nAn environment variable is just a bit of data that you can access from your shell. You can create them, you can change them, and there are some which are set for you by the system or the shell to help you out.\nTry the following command:\necho \u0026#34;My current working directory is: $PWD\u0026#34; You should see something like this:\nThe dollar symbol is used to tell the shell we want to use the PWD variable, not write out the text PWD. We'll see a lot more about environment variables as we continue through the book.\nListing the Contents of the Working Directory In the graphical user interface, we can also see the files and folders in the current directory. In the shell, we don't see this content. But we can show the contents of the current working directory with the following command:\nls You should see something like this:\nThe ls command is the List Directory Contents command. It will show the contents of a directory. If we don't give it any parameters, it will show the contents of the current directory.\nThere are a lot of options for the ls command. In Chapter 5 we'll see how to find out the options for commands. For now, let's look at one of the most common options -l. This shows the contents as a list:\nls -l A little like the \u0026lsquo;details\u0026rsquo; view in a graphical user interface, this list view shows us more details, such as who owns the file or folder, when it was modified, and more. Again, we'll see more details on this later.\nChanging the Directory In a graphical user interface, you move to a different directory by clicking on it.\nIn the shell, you run the cd command. Try it out with:\n# Move to the pictures directory... cd Pictures # ...then list the contents of the directory. # Note that the \u0026#39;-al\u0026#39; flags mean show *all* files, as a *list*. ls -al Note that when you see shell commands, everything which starts with a hash symbol is a comment. These comments are just for readability, you don't need to include them. But if you are saving your own shell snippets (or \u0026ldquo;scripts\u0026rdquo;), then you might find comments a useful way to remind yourself of what you are hoping to achieve with the commands, or to make the script more readable.\nOn my system, we'll see the following output:\nThe cd command is the Change Directory command. You might see a pattern here - shell commands often are very short (to make it easier to type them quickly) and are often made up of the first letters of the description of the command (pwd for Print Working Directory, cd for Change Directory).\nNow that you know how the cd command works, you will be able to move around to different folders. At this stage, it's important to talk a little bit about how paths work in systems.\nUnderstanding Paths In Linux, Windows and MacOS (and most other operating systems), paths are the \u0026lsquo;addresses\u0026rsquo; of files or folders.\nThere are two types of paths - Absolute Paths and Relative Paths. An absolute path is one which gives the exact location of a file. For example, on my computer, the absolute path to the folder I am writing this book in is:\n/Users/dwmkerr/repos/github/dwmkerr/effective-shell Absolute paths always start with a slash. That's how the system knows it is an absolute path. The / is the root of the file system - basically it's the folder which everything else lives in.\nIf I have an absolute path, I know exactly where the file or folder is. Let's compare this to a relative path. Below is the relative path in my shell for the file I'm writing right now:\nwebsite/content/docs/part-1-transitioning-to-the-shell This path is relative to my current working directory in the shell. This means that this path only makes sense if you use it from a specific directory. If I am in my Pictures folder, and I want to move to the 2020-photos folder, I could do it in two ways. The first is with an absolute path:\ncd /Users/dwmkerr/Pictures/2020-photos The second is with a relative path:\ncd 2020-photos In short - relative paths are often useful if you want to move to something within the current directory and absolute paths are useful if you need to move to somewhere completely different.\nThe Special Dot and Dot Dot Folders As you experiment with these commands, you might have noticed that every folder contains two other folders, one with the name . and one with the name ... Run ls -al on the pictures folder to see an example:\nls -al pictures You should see something like this:\nThis picture highlights two special folders - . and ... These are special folders which exist in every folder in the system.\nThe first folder, ., represents the folder it is in. Why would this be useful? Well, sometimes we just want a quick way to say the equivalent of \u0026ldquo;right here\u0026rdquo; in a command. For example, if I wanted to copy the current folder to a backup folder, I could do this:\ncp . /backup The cp command is the Copy command, and we'll see it in the next chapter. But the key thing to note is that we can use . to tell the command to copy the folder we are in right now.\nThe .. folder means the parent folder. You can use this to \u0026ldquo;go up\u0026rdquo; to the parent folder, for example:\ncd .. ls . Would give:\nNote that we've used cd .. to change directory to the parent folder then ls to list the contents of the current folder. We could also just have used ls on its own as it defaults to the current folder.\nThe .. folder can be helpful if you need to navigate to a location which is outside of your current folder. For example, if I am in the pictures folder and I want to move to the scripts folder, I can just use:\ncd ../scripts ls And we'll see this:\nThe Home Directory There is one more special part of the file system we have to know about. That is the Home Directory. In Linux-like systems every user has their own personal directory where they can keep their files and folders.\nThis directory can always be accessed through the ~ character. For example, no matter where I am in the system, I can run the following command to move to my home directory and show the contents:\ncd ~ ls This would show something like this:\nThis makes moving around your home directory very easy. For example, on a Mac, to go to your pictures folder from anywhere, you can always just run:\ncd ~/Pictures Your home directory on most computers will be where you keep your documents, pictures, videos and so on. Normally this directory is not accessible to other users of the system. Each user in a system gets their own home directory.\nYou can also see the home directory by using the special HOME environment variable:\necho \u0026#34;My home directory is: $HOME\u0026#34; This would show something like this:\nOne useful trick - running cd without any parameters will always take you home! So to go home, just run:\ncd Now that we know about relative paths, absolute paths, and the special dot and dot dot folders, and the home directory we can continue learning how to navigate the shell!\nPushing and Popping the Working Directory One thing we might want to do is quickly move from one location to another, then go back again. Let's say for example I am working in on this chapter, but I want to check my downloads. One way to do this is with this pushd command:\npushd ~/Downloads ls popd After I've checked my downloads, I can run popd to go back to where I was:\nThe pushd command \u0026lsquo;pushes\u0026rsquo; a new working directory onto a stack - moving you there. The popd command \u0026lsquo;pops\u0026rsquo; the working directory off the top of the stack. A stack is a structure often used in computers; we can actually push lots of different files to the working directory stack.\nWhy is it called a stack? Well, the reason is that if we were to visualise the structure, it might look like a stack of plates or similar. Here's how pushd and popd would look if we were to visualise it:\nThese commands can be useful if you need to move to other locations but want to be able to quickly go back to where you were before afterwards.\nGoing Back One last trick which can save time is the following command:\ncd - This is a special parameter for cd which tells it to go back to the last location you moved to. Here's how it might look if you use it:\nThis can only be used to go back to the last directory. If you need to be able to go backwards multiple times or through a history of directories, you might need to use pushd and popd instead.\nSummary In this chapter we introduced the following:\n The pwd (print working directory) command shows the current working directory The $PWD environment variable holds the current working directory The ls (list) command shows the contents of the current directory or a given directory The ls -l command shows the contents of the current directory as list The cd (change directory) changes the current working directory Absolute paths are paths which specify the exact location of a file or folder\u0026hellip; \u0026hellip;Relative paths are paths which are relative to the current directory The . special folder means \u0026lsquo;this folder\u0026rsquo; The .. special folder means \u0026lsquo;the parent folder\u0026rsquo; The ~ special folder is the \u0026lsquo;home directory\u0026rsquo; The $HOME environment variable holds the user's home directory You can run cd at any time to quickly go to your home directory You can use pushd and popd to push and pop the working directory stack You can use the cd - command to go back to the last location  "});index.add({'id':3,'href':'/docs/part-1-transitioning-to-the-shell/3-managing-your-files/','title':"Chapter 3 - Managing Your Files",'content':"Chapter 3 - Managing Your Files Downloading, unzipping, copying, moving, renaming and deleting files in a graphical user interface is normally fairly intuitive. Now we'll learn how to perform the same operations in a shell. Once you can organise your files, you are well on your way to being able to use the shell more effectively for day to day tasks.\nNow that we know how to organise the files in our computer, we'll take a look at how to download files, create new files, preview the contents of files, open files, copy, move and delete files.\nThis chapter will introduce the wget, unzip, cp, mv, rm, mkdir, rmdir, cat and zip commands. We'll also briefly look at wildcards and redirection.\nCreating a Playground Before we start copying, deleting, moving and renaming files, we should create a \u0026lsquo;playground\u0026rsquo; area we can work in. We don't want to test all of this on our own personal files until we know exactly what we're doing!\nTo help with this, I've created a zipped up folder which has a lot of files in it which we can use to play with. Now the file itself is available on the effective-shell.com website, right here:\neffective-shell.com/downloads/effective-shell-playground.zip\nWe could open up a web browser, download the file, unzip it and then start from there, but this book is all about how to deal with every day tasks in your shell, so let's skip the browser and do it in the shell instead!\nOpen your shell - if you've not yet got set up with your shell, that's OK, just check Chapter 1 - Getting Started.\nNow that you have your shell open, we can run the wget command (Web Get) to download the zip file. Let's download it to our Home folder. If you are not sure what the Home folder is, check Chapter 2- Navigating Your System.\nFirst, we'll move to our home directory, then download the file.\ncd wget https://effective-shell.com/downloads/effective-shell-playground.zip You'll see something like this:\nWhen you call the wget command, you can give it any web address and it'll download it to your current folder. It also shows the progress of the download interactively (particularly useful if it's a big file!).\nAs an aside, if we were not in our home folder when we called the wget command, we'd download the file to wherever we are currently working in. If we wanted to be explicit about where we download the file, we can use the -O (Output File) flag to say explicitly where we want to download the file.\nAs an example, if were not in the home folder, but wanted to download there, we'd just call:\ncd wget -O ~/playground.zip https://effective-shell.com/downloads/effective-shell-playground.zip Now that we've downloaded the file, let's look at our home directory now, with a quick call to ls ~:\nCool - we have the zip file downloaded! Now we need to work out how to unzip it so we can get to the files in the zip archive.\nFinding out about files One of the interesting things you can do in a shell is ask it to tell you more about a file. This can be useful if we've got a file, and we're not sure what it might be. Let's try it out now:\nfile ~/effective-shell-playground.zip The file command is showing us we have a zip file - now it's time to unzip it!\nExtracting the Zip Right now we have a zip file. We need to extract it, unpack the files so that we can play with them. Again, in a system with a graphical user interface, this is easy, generally you just double click on it. But we're going to use the shell for this!\nRun the command:\nunzip ~/effective-shell-playground.zip Now let's look at what we've got with the ls command:\nExcellent - we've now got a folder which contains all of the files in the zip archive.\nDeleting Files Now that we've downloaded and unzipped the file, we don't need the zipped version any more. So let's delete this file.\nThe rm (Remove) command can be used to delete a file. If we run:\nrm ~/effective-shell-playground.zip ls Then we'll see the following:\nNotice that the zip file is gone - just the folder is left.\nBy the way - be really careful with the rm command. Unlike in a graphical interface, it won't put files you delete into a recycle bin, they are blatted forever! In a later chapter we'll see some ways to change this behaviour for your local machine, but always remember rm is a little risky!\nHowever one thing it will do to try and help you not make mistakes is let you know if you are trying to delete a folder, not a file.\nRun the following command to try and delete the unzipped folder:\nrm ~/effective-shell-playground The rm command has not succeeded in this case - it's warning us that we're not deleting a file, but a whole directory.\nNow we can get around this by adding the -r flag, which means \u0026lsquo;recursive\u0026rsquo; - i.e. not just the folder but everything in it. But use this with caution!\nExamining the Contents of a Folder Let's take a look at what is in the playground. By the way, the output you see on your computer might have a few more files in it as I might have added some after writing this article!\nIn a graphical user interface, we'd open the folders and look at the files. In the shell, we can use the tree command to show the contents of a folder.\nNow the tree command is not installed by default on all systems. So if you are on a Mac, run:\nbrew install tree If you are on Linux, you will likely already have it. If you don't, use your distributions package manager to get it (e.g. apt-get install -y tree).\nUsing a non-universal command is generally not our goal in this book, but in these early stages while we are transitioning from the graphical user interface, the tree command can be really helpful. Later on we'll see how to use the more universal find command to give a similar output.\nTry it out with:\ntree ~/effective-shell-playground The tree command shows you all of the folders and files in a location. If we are unsure what one of the files is, we can ask the shell to give us more info. For example, I could find out more about the loas-gch.JPG file by running:\nfile ~/effective-shell-playground/pictures/loas-gch.JPG Note that the file command is already showing it is a bit more clever. It knows that the file is a JPEG file (a picture), but is giving other details as well.\nCopying a File Let's say we really love that photo, and we want to make a copy of it. We can do that easily by using the cp (_Copy) command:\ncp ~/effective-shell-playground/pictures/laos-gch.JPG ~/effective-shell-playground/pictures/laos-gch-copy.JPG This makes a copy of the file - if you are not sure if it has worked, just run:\ntree ~/effective-shell-playground We can see we've made a copy.\nSaving Some Keystrokes Wow, it's painful putting ~/effective-shell-playground before everything! From Chapter 2- Navigating Your System we already know how to change directory, so let's do that now:\ncd ~/effective-shell-playground Remember - cd is change directory. Excellent - until we tell our shell otherwise, this our new working directory.\nRenaming or Moving Files You might have noticed that the photos have different endings - one of them ends in .JPG. Let's rename it so that it has the ending .jpeg to be consistent with the others.\nTo do this, we use the mv (Move) command. When it comes down to it, moving a file or renaming a file amount to the same kind of operation, so one command can do both.\nRename the copy we made of the photo by running:\nmv pictures/loas-gch-copy.JPG pictures/loas-gch-copy.jpeg Let's run tree to see what happened. Remember - now that our working folder is the playground, we don't even need to tell tree where to look, if we give it no arguments it'll assume we're looking at the working directory:\nMuch nicer! Now our copied file has been moved to have a new name. It's in the same folder still, but you can use mv to also change what folder a file is in.\nCreating a New Folder Perhaps we're not happy with the name pictures for our folder we've been playing with, maybe we'd prefer to have them all in a folder called photos?\nProbably the first thing we'd do in a graphical environment is create a new folder - so let's do thee same here!\nRun the commands:\nmkdir photos tree And we should see:\nWe've use the mkdir command, which is short for Make Directory. This is how we create a new folder in the shell.\nNow let's say we wanted to be really organised, and create a photos folder by year and topic, perhaps 2019/outdoors/pictures. In a graphical user interface, we'd have to create each folder one at a time. In the shell, it's easy!\nmkdir -p 2019/outdoors/pictures tree Let's see how it looks:\nAll we had to do was add the -p flag (which means \u0026ldquo;make the parent folder if it doesn't already exist) and we can create a whole set of subfolders. Now we're starting to see why knowing the shell can be powerful - if you know you have this trick up your sleeve you can be doing things like re-organising files more effectively in a shell than in your graphical user interface!\nDeleting a Folder Now that we have our more organise 2019/outdoors/photos folder, we don't need the photos folder we created. So let's delete it! Remember how rm removes a file, and mkdir creates a folder? Well rmdir will remove a folder!\nrmdir photos tree As an important sidenote, just how rm doesn't move files to your recycle bin, so you cannot undo the operation, rmdir works the same way. So if we try to remove a directory which has things in it, such as the pictures directory, it will fail:\nrmdir pictures In this case, it is actually easier to just call rm -r pictures. Why is that? Well it's just like we saw in the earlier example - rm can delete files or directories. And if the directory is not empty, we just add the -r (Recursive) flag to tell it to delete the directory and everything it contains.\nCopying Multiple Files Now we need to copy over our files from the pictures folder to the 2019/outdoor/photos folder. We'll use exactly the command we used before to copy a file - cp:\ncp pictures/* 2019/outdoor/photos tree Here we've used the wildcard symbol, which is *, to say \u0026ldquo;everything in the folder\u0026rdquo;. Many commands can take wildcards as inputs. We'll see much more about them later!\nLooking at Text Files Run tree and you'll see we have a quotes folder:\ntree We're going to use the cat (Concatenate) command to look at the Ursula Le Guin quote. Run the following command:\ncat quotes/ursula-le-guin.txt In the screenshot we snuck in a quick file call to see what the shell thinks the file is.\nWhy Concatenate? We're just showing the text in the terminal, not concatenating (i.e. joining) anything! Well the reason is that the cat command does concatenate files (i.e. puts them together), it's just that we only gave it one file, so it had nothing to join it to. By default, cat writes the output to the screen, so this is one of the most common ways you'll see to quickly look at the contents of a file.\nWe'll see a lot more about how this works later, and how you can then take that output and put it somewhere else. But for now, let's finish with a couple of tricks.\nFirst, let's just cat the whole folder:\ncat quotes/* There we see the * wildcard again. We could be more specific and use something like cat quotes/*.txt to only show files ending in .txt.\nNotice how the output from all of the files has been concatenated together into a single output? That's where the cat name comes from - it concatenates, i.e. joins files.\nAs one last trick, let's use this output but instead of showing it on the screen, put it into a single all-quotes.txt file:\ncat quotes/* \u0026gt; quotes/all-quotes.txt tree cat quotes/all-quotes.txt The \u0026gt; part of this is called a redirect operator - in short it's telling the shell not to write to the screen, but to write to a file. We've concatenated all of the individual quotes and made a single file from them.\nWe'll look at wildcards and redirection in a lot more detail as we continue through the book!\nZipping up Files Let\u0026rsquo; say that we want to zip up the new 2019/outdoors/pictures folder. We've already seen the unzip command, let's see how to use the zip command to zip up a folder:\nRun the command below:\nzip -r 2019-outdoor-pictures.zip 2019 This is how it will look - there's a tree and ls command before and after so we can see what's happening!\nGreat! We've created a zip. Let's dissect the command a bit:\n zip just means call the zip executable -r means recursive we don't just want to zip the 2019 folder, we want to zip everything inside it as well! 2019-outdoor-pictures.zip is the name of the file we want to create, we put this first\u0026hellip; \u0026hellip;because everything which follows (e.g. 2019) is going to be zipped, and we can specify many files and folders if we want  Summary In this chapter we introduced the following:\n The wget (web get) command can download a file from the web. If we use the -O (output location) flag, we can specify where we want to download the file to. The file command can be used to ask the shell what it thinks a file is (this is quite useful because unlike on some systems, not all files in Linux have a file ending). The unzip command can unzip a file for us. The rm (remove) command can delete a file. The rm command won't delete a folder which has files in it, unless you tell it to by adding the -r (recursive) flag. The tree command can show the files and folders in a given directory, or the current directory by default. The cp (copy) command can copy a file. The cp can also be given wildcards like * to copy many files. The mv (move) command can move or rename a file. The mkdir command can create a folder - it can even create a whole tree of folders if you pass the -p (_create parent directories) flag. The rmdir command can delete a folder - but just like rm it will fail if the folder is not empty! When we delete files in the shell with rm or rmdir they are gone forever, no recycle bin! The cat command (concatenated) can be used to write the contents of a file to the screen. We can pass multiple files to commands like cat if we use wildcards, such as quotes/*. We can write the output to a file instead of the screen, if we use the \u0026gt; (redirect to file) operator.  "});index.add({'id':4,'href':'/docs/part-1-transitioning-to-the-shell/4-clipboard-gymnastics/','title':"Chapter 4 - Becoming a Clipboard Gymnast",'content':"Chapter 4 - Becoming a Clipboard Gymnast For those who are new to the shell, we've covered a lot. In this chapter we'll slow down the pace of new commands a bit and instead focus on a core skill which you will already be familiar with from Graphical User Interfaces - using the clipboard.\nYou have probably already been using the clipboard with the shell, copying and pasting commands and their outputs. However, there's a lot more we can do with the clipboard. Now we'll look at how to take this to the next level.\nWe'll also briefly introduce introduce aliases and pipelines, which will be covered in a lot more detail in later chapters.\nThe Clipboard Essentials I wouldn't be surprised if the keyboard shortcuts to access the clipboard are already firmly locked into muscle memory for almost all readers, but just in case, here's a reminder of the shortcuts across different systems:\n   Command Windows Shortcut Linux Shortcut MacOS Shortcut     Cut Ctrl + X Ctrl + X ⌘ + X   Copy Ctrl + C Ctrl + C ⌘ + C   Paste Ctrl + V Ctrl + V ⌘ + V    In the shell, you may find that these commands don't run as expected. For example, in the screenshot below I have tried to use Ctrl + V a few times to paste into terminal on Ubuntu:\nInstead of the contents of the clipboard being dropped into the shell, we see the text ^V. Why is this?\nWell, some of this is historical (the shell has been around for a long time so we'll see this answer a lot!). The reason the Ctrl key is called the Control Key is that it is used to send control sequences to the computer. When we're using the Control Key, the characters we send are not plain text, they're used to perform actions. This is something that is probably pretty familiar. For example, Ctrl + P is almost universally used as a shortcut for the \u0026lsquo;Print\u0026rsquo; command.\nWe tend to think of these commands as shortcuts to save us from finding the appropriate command in a menu or on a toolbar. But of course most shells and command-line interfaces pre-date graphical user interfaces. They needed a way to differentiate between a user entering plain old text, and a user wanting to execute a certain command.\nEven modern shells tend to follow the conventions around control sequences which were established by earlier ones to ensure a consistent experience for users who are used to working with shells. Shells have a whole bunch of control sequences which actually pre-date the graphical user interface, the clipboard itself, and even screens!\nSome of the control sequences used in the shell you might already be familiar with. For example, if you have a program running and want to cancel it, you might be used to using Ctrl + C. This actually sends a signal to the program and typically the program responds by closing. We'll see signals again and again as we go through the book.\nThe Ctrl + C combination terminates the current program. What about Ctrl + V? This is the grand-sounding \u0026ldquo;Verbatim Insert\u0026rdquo; command. It tells the shell to write out the next keystroke you give it. This allows you to write out \u0026lsquo;special\u0026rsquo; characters like the escape key, left or right keys, or even the Ctrl + V combination itself.\nSo if you type Ctrl + V twice, the shell writes out the text ^V. The hat symbol ^ represents Ctrl. The first command tells the shell to write out the following command, the second is then written out directly. You can try writing out some different sequences. You'll see various odd looking symbols drawn, which represent things like the Alt key and other special keys.\nSo why do we need to care? Well the shell already has a command for Ctrl + C and Ctrl + V, so we're going to need to work around this to use our familiar \u0026lsquo;copy\u0026rsquo; and \u0026lsquo;paste\u0026rsquo; commands.\nHow this works varies across platforms. Follow the instructions below for the platform you are using.\nWindows\nIf you are using a Command Prompt, then the usual shortcuts will work fine. However, most of the time we will be using Bash. In this case the shortcuts will not work. Instead, select the Use Ctrl+Shift+C/V as Copy/Paste option from the properties menu:\nYou can now use Ctrl+Shift+C for copy and Ctrl+Shift+V for paste. You can also copy text by just dragging the cursor over it with the right mouse button.\nLinux\nOn most Linux systems you'll be using the Gnome terminal, which means that you can use Ctrl+Shift+C for copy and Ctrl+Shift+V for paste. You can also right click on text with the cursor to select it.\nMacOS\nMac users can just use ⌘ + C for copy and ⌘ + V for paste. The shell doesn't use the special Mac Command character ⌘, which means the default keyboard mappings on MacOS work fine in a shell as they do not clash with anything.\nNow that we've got the basics out of the way, and learnt far more than we probably wanted to about control keys, we can look at more ways to use the clipboard.\nPreparing the Clipboard Commands Copying and pasting text to and from the clipboard is useful, but there's a lot more we can do. With a couple of basic commands we can hugely expand what we can do with the shell and make a whole set of everyday tasks far easier to accomplish.\nThere is one small complexity we'll need to work through before we continue. The complexity is that the clipboard is accessed in different ways on Windows, Linux and MacOS. I'll first show you how to deal with this, just follow the instructions for the platform you are working on.\nTo make things easier for the reader I'm going to assume you have created the pbcopy and pbpaste commands by following the instructions below. I am creating these commands so that regardless of the platform you are using the tutorials will work in the same way!\nWindows\nAssuming you are using WSL, you will need to run the following two commands. By the time this book is published there may be a cleaner way, but for now this is a workaround for some limitations on the WSL system:\nalias pbcopy=\u0026#39;clip.exe\u0026#39; alias pbpaste=\u0026#34;powershell.exe -command \u0026#39;Get-Clipboard\u0026#39; | tr -d \u0026#39;\\r\u0026#39; | head -n -1\u0026#34; Don't worry about how these commands work - by the time you've gone through the book it should make perfect sense. For now you just need to know we're adding two new commands to our toolkit - pbcopy and pbpaste, which will work in Bash on Windows.\nLinux\nHopefully if you are Linux user the commands below will seem familiar. They install the xclip program and create shortcuts to copy and paste. You absolutely don't need to do this if you prefer to call xclip directly, these commands are just setup so that across all platforms the tutorial looks the same.\nsudo apt install -y xclip alias pbcopy=\u0026#34;xclip -selection c\u0026#34; alias pbpaste=\u0026#34;xclip -selection c -o\u0026#34; MacOS\nNothing is required on MacOS - pbcopy and pbpaste are built in.\nMaking these changes permanent\nWe've used the alias command to create pbcopy and pbpaste. In Bash (and most shells) an alias is something you can configure as a shortcut to avoid having to type longer commands. There's a whole chapter on commands in Section 2.\nThese instructions will need to be repeated when you re-open your terminal. In a later chapter we'll see how to make permanent customisations to our shells so that we don't have to repeat this setup.\nWe'll also see later on how to create configuration which works across many different platforms, so that you can use the same configuration regardless of what platform you are working on. This is very useful if you work across multiple machines or operating systems!\nCopy and Paste Basics Now that we've created these commands, we can use them to access the clipboard. For example, if I copy the following text:\nKirk Van Houten Timothy Lovejoy Artie Ziff Then I can paste it into the shell with the following command:\npbpaste And we'll see something like this:\nCopying is just as straightforward. If you have downloaded the Effective Shell \u0026lsquo;playground\u0026rsquo; folder you can see we have a list of characters from \u0026ldquo;The Simpsons\u0026rdquo; in the file playground/text/simpsons-characters.txt. Now we could use the cat command to show the contents of the file, and then manually select the text and copy it. Even easier though is to just pipe the contents of the file to the pbcopy command:\ncat ~/playground/text/simpsons-characters.txt | pbcopy The output will look similar to the below (I've included the output of cat for reference as well):\nThe vertical bar | is the pipe operator. It tells the shell to take the output from the command on the left and send it straight to the input of the program on the right. We're going to see a lot more of the pipeline operator as we continue. For now it's enough to know you can use it to \u0026lsquo;chain\u0026rsquo; commands together.\nThis might not seem super useful so far - but if the text file was a lot larger then it would be much harder to cat it out, use the mouse to select all of the text (scrolling up through the window) and then copy it. And if you didn't have a mouse, it would be even more tricky. We're aiming to be as effective as possible when using the shell so being able to use the keyboard quickly for common tasks is critical.\nNow we can see some real world examples of how these commands can be useful in daily tasks!\nRemoving Formatting Don't you hate it when you have to copy formatted text and don't have an easy way to paste it as unformatted text? Here's an example, I want to copy this Wikipedia page on \u0026lsquo;bash\u0026rsquo;, and paste it into a Word document:\nMany programs have a shortcut to paste the contents of the clipboard (such as \u0026lsquo;command + shift + v\u0026rsquo;) but if you are like me you might find yourself pasting into a plain text editor just to copy out the plain text.\nIf you just run the command pbpaste | pbcopy, you can easily strip the formatting:\nWe're just piping out the clipboard (which ends up as plain text, cause we're in a terminal!) and then piping that plain text back into the clipboard, replacing the formatted text which was there before.\nThis little trick can be very useful. But we can use the same pattern to quickly manipulate the contents of the clipboard in more sophisticated ways.\nSorting Text Because we can pipe the contents of the clipboard to other programs, that means we can easily use the huge number of tools available to us to work with text.\nLet's take another look at the list of characters we have in the ~/plaground/text/simpsons-characters.txt file:\n$ cat ~/playground/text/simpsons-characters.txt Artie Ziff Kirk Van Houten Timothy Lovejoy Artie Ziff Nick Riviera Seymore Skinner Hank Scorpio Timothy Lovejoy John Frink Cletus Spuckler Ruth Powers Artie Ziff Agnes Skinner Helen Lovejoy We can easily take this text, sort it and then directly copy the results:\n$ cat ~/playground/text/simpsons-characters.txt | sort | pbcopy The contents of the clipboard will now contain:\nAgnes Skinner Artie Ziff Artie Ziff Artie Ziff Cletus Spuckler Hank Scorpio Helen Lovejoy John Frink Kirk Van Houten Nick Riviera Ruth Powers Seymore Skinner Timothy Lovejoy Timothy Lovejoy The sort command has lots of different options but the defaults work fine for this case. We can see we've got quite a few duplicates - now we can move onto how we'd handle that.\nManipulating Text Let's say someone has emailed me a list of people I need to invite to an event:\nThe problem is:\n The list is in Excel and is formatted The list has duplicates I need to turn each name into an email address like 'Artie_Ziff@simpsons.com\u0026rsquo;  I want to email get the email addresses on my clipboard ready to paste into my email client quickly. We can quickly handle this task without leaving the shell.\nIf you want to try out the same commands and follow along you can copy the raw text below (don't worry if the commands are unfamiliar, we'll be seeing them again and again and breaking down each one in later chapters):\nArtie Ziff Kirk Van Houten Timothy Lovejoy Artie Ziff Nick Riviera Seymore Skinner Hank Scorpio Timothy Lovejoy John Frink Cletus Spuckler Ruth Powers Artie Ziff Agnes Skinner Helen Lovejoy First, we copy the text to the clipboard.\nNow we can paste and sort:\n$ pbpaste | sort Agnes Skinner Artie Ziff Artie Ziff Artie Ziff Cletus Spuckler Hank Scorpio Helen Lovejoy John Frink Kirk Van Houten Nick Riviera Ruth Powers Seymore Skinner Timothy Lovejoy Timothy Lovejoy Then remove the duplicates:\n$ pbpaste | sort | uniq Agnes Skinner Artie Ziff Cletus Spuckler Hank Scorpio Helen Lovejoy John Frink Kirk Van Houten Nick Riviera Ruth Powers Seymore Skinner Timothy Lovejoy Replace the space with an underscore:\n$ pbpaste | sort | uniq | tr \u0026quot; \u0026quot; \u0026quot;_\u0026quot; Agnes_Skinner Artie_Ziff Cletus_Spuckler Hank_Scorpio Helen_Lovejoy John_Frink Kirk_Van_Houten Nick_Riviera Ruth_Powers Seymore_Skinner Timothy_Lovejoy Then add the final part of the email address:\n$ pbpaste | sort | uniq | tr \u0026quot; \u0026quot; \u0026quot;_\u0026quot; | sed 's/$/@simpsons.com/' Agnes_Skinner@simpsons.com Artie_Ziff@simpsons.com Cletus_Spuckler@simpsons.com Hank_Scorpio@simpsons.com Helen_Lovejoy@simpsons.com John_Frink@simpsons.com Kirk_Van_Houten@simpsons.com Nick_Riviera@simpsons.com Ruth_Powers@simpsons.com Seymore_Skinner@simpsons.com Timothy_Lovejoy@simpsons.com This looks perfect! We can now put the transformed text back onto the clipboard:\n$ pbpaste | sort | uniq | tr ' ' '_' | sed 's/$/@simpsons.com' | pbcopy All in all we have the following pipeline:\n pbpaste - output the clipboard sort - order the output uniq - deduplicate the rows tr ' ' '_' - replace spaces with underscores sed /$/@simpsons.com - add the email domain to the end of the row  Now you don't need to remember all of these commands. We'll be going into them in detail as the book continues, and in the next chapter we'll be looking into how you can get help directly in the shell to discover how commands work. The key concept is that you can treat the clipboard just like a file - reading from it, manipulating it, and writing back to it, without ever leaving the shell.\nIn fact - if you are on a Linux system, try running:\ncat /dev/clipboard You'll see the contents of the clipboard written out. In Linux almost everything can be represented as a file - the clipboard included! Like a lot of the other topics this is something we'll visit again in detail later.\nWe're also going to spend a lot of time later on looking at pipelines in detail, so don't worry too much if this seems overwhelming at this stage!\nAs you go through the book you'll be able to apply every technique you learn to the clipboard itself - hopefully you'll find this can save you a lot of time and make you even faster with your day to day work.\nSummary In this chapter we learnt:\n You can copy and paste into the shell with keyboard commands which are the same, or at least very similar, to the commands you normally use. Different operating systems access the clipboard in different ways, but we can work around this by creating an alias command (which we'll see in detail later) We can use pbcopy to copy and pbpaste to paste. We can \u0026lsquo;chain\u0026rsquo; commands together with the | (pipe) operator. We can turn formatted text on the clipboard into plain text by just running pbpaste | pbcopy. We can sort lines of text with the sort command. There is clearly a lot more we can do with text as we save hints of with the uniq, tr and sed commands - which we'll introduce in detail later. You can treat the clipboard a bit like a file in the shell. On Linux, lots of things can be represented as files - including the clipboard (which is accessed via the /dev/clipboard file).  "});index.add({'id':5,'href':'/docs/part-1-transitioning-to-the-shell/5-getting-help/','title':"Chapter 5 - Getting Help",'content':"Chapter 5 - Getting Help In the earlier chapters I've introduced quite a few commands. Having to remember all of these commands and their parameters would be very hard. Fortunately there are built-in capabilities in the shell to help.\nIn this chapter I'll show you how to quickly get help when working with tools in the shell, without disrupting your flow!\nGetting Help is Important! If you are trying to be more effective when using the shell, it is crucial to know how to quickly look things up.\nThere'll be many circumstances where you'll need to open a browser to search for help. But there's also a wealth of information only a few keystrokes away. Looking up parameters, checking how to run commands, C library documentation, or even useful information like ASCII charts are available directly in the shell.\nBeing able to access this information quickly, without jumping into a browser or interrupting your flow is going to be one of the most crucial things you can do to become an effective shell user.\nFirst we're going to look at the standard help system which is available on all Unix-like systems, which is man (short for \u0026lsquo;manual\u0026rsquo;). Then we'll see a useful tool you can installed called tldr, which might be more helpful for day-to-day use. Finally we'll take a look at the cht.sh site as an alternative source for help.\nUnderstanding \u0026lsquo;man\u0026rsquo; Most tools you encounter in the shell have manual pages available. Many people will be familiar with the man command to get help on a tool, but there is a lot more help available than people often realise.\nGetting help on a command The most basic way to get help on a command is with man. Here's an example:\n$ man cp CP(1) BSD General Commands Manual CP(1) NAME cp -- copy files SYNOPSIS cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ... target_directory DESCRIPTION In the first synopsis form, the cp utility copies the contents of the source_file to the target_file. In the second synopsis form, the con- tents of each named source_file is copied to the destination target_directory. The names of the files themselves are not changed. If cp detects an attempt to copy a file to itself, the copy will fail. ... The man command opens the manual for the given tool. These manuals should contain all command line options and details of how to use the tool.\nYou can scroll up and down through the content with the arrow keys. This scrolling capability actually is not part of man - it is available because the information is presented in the shell pager. A pager is a tool for looking through content which might not easily fit on a screen.\nUsing the pager The first thing you might notice is that you can move through the manual pages with the arrow keys.\nThe man command finds the appropriate manual page (often shortened to \u0026lsquo;manpages\u0026rsquo;) and then opens the page in a pager tool. The pager is what is providing the keyboard interface to look through the file.\nOn most systems, the pager will be the less program. There are lots of commands you can use to navigate through files with less, but the bare essentials are:\n d - Scroll down half a page u - Scroll up half a page j / k - Scroll down or up a line. You can also use the arrow keys for this q - Quit /\u0026lt;search\u0026gt; - Search for text n - When searching, find the next occurrence N - When searching, find the previous occurrence  There are many other commands, but the set above is normally what I find myself using the most.\nIf you are interested, you can actually see what your pager is with the command below:\n$ echo $PAGER less The $PAGER environment variable is used to tell the shell what program to use for paging. A few more details can be found with the man man command.\nYou can put any text content into your pager - try this:\nls -al /usr/bin | less This lists the contents of the /usr/bin folder, piping the output to less so we can easily scroll through it.\nThere are alternative pagers available (on many Unix-y systems you'll have less, more and most) but in general you'll normally get what you need with less.\nThe Alternative - Help Sometimes you'll look something up in the manual and get the \u0026lsquo;builtins\u0026rsquo; page. For example:\n$ man cd BUILTIN(1) BSD General Commands Manual BUILTIN(1) NAME builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break, breaksw, builtins, case, cd, chdir, command, complete, continue, # (I\u0026#39;ve skipped the bulk of the output to save space!) This happens when the command you are looking up is not actually a program with a manual page, but a built-in shell command. Most shells have a way get help on such commands - bash for example has help:\n$ help cd cd: cd [-L|[-P [-e]] [-@]] [dir] Change the shell working directory. Change the current directory to DIR. The default DIR is the value of the HOME shell variable. # (I\u0026#39;ve skipped the bulk of the output to save space!) This is all I'll say about help for now. We visit it again in [Chapter 10 - Understanding Commands](/docs/part-2-core-skills/10-understanding-commands/, where we talk more about built-in commands. For now we'll go back to the man command, which works across all shells as it is a Linux feature rather than a shell specific feature!\nManual Sections You'll often see tools referred to in manpages with numbers after them. Take a look at man less:\nThe number is the manual Section Number. The different sections of the manual are documented be found on most Unix-like systems in man's documentation, which you can check by running man man1. Here's what you'd get on Ubuntu 16:\n Section 1 - Executable programs or shell commands Section 2 - System calls (functions provided by the kernel) Section 3 - Library calls (functions within program libraries) Section 4 - Special files (usually found in /dev) Section 5 - File formats and conventions (e.g. /etc/passwd) Section 6 - Games Section 7 - Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7) Section 8 - System administration commands (usually only for root) Section 9 - Kernel routines (Non standard)  Not all of these explanations will be entirely clear to everyone, so we'll go through the sections in detail shortly.\nIf you want to, you can specifically choose which section of the manual you are looking in by using:\nman \u0026lt;section\u0026gt; \u0026lt;search\u0026gt; You can also get more information about the sections themselves by opening up the intro page. For example:\n$ man 1 intro INTRO(1) BSD General Commands Manual INTRO(1) NAME intro -- introduction to general commands (tools and utilities) DESCRIPTION Section one of the manual contains most of the commands which comprise... Why would you do this, and why would you care? In general you won't need to worry about the sections unless you are looking for something which has an entry in multiple sections and you want to specify which one you use.\nAnother reason it is useful to know about the sections is that a lot of documentation (online and offline) includes a section number after the name of a command or file. Knowing what the section is can be useful in this case.\nHere are a few examples of entries from each section, which illustrate what each section is for.\nSection 1: Programs and Shell Commands These are programs - probably what you are going to be looking up most regularly! For example, man 1 time shows:\nTIME(1) BSD General Commands Manual TIME(1) NAME time -- time command execution SYNOPSIS time [-lp] utility DESCRIPTION The time utility executes and times utility. After the utility finishes, time writes the total time elapsed, the time consumed by system overhead, and the time used to execute utility to the standard error stream. Times are reported in seconds. ... Section 2: System Calls You'll probably not use this section unless you are doing systems programming2. This section contains info on the available Linux Kernel system calls. For example, running man 2 chown gives:\nCHOWN(2) BSD System Calls Manual CHOWN(2) NAME chown, fchown, lchown, fchownat -- change owner and group of a file SYNOPSIS #include \u0026lt;unistd.h\u0026gt; int chown(const char *path, uid_t owner, gid_t group); ... This entry shows you how you would call the function if you were programming for the Kernel.\nSection 3: Library Calls These are the manpages for the C standard library functions. For example, man 3 time:\nTIME(3) BSD Library Functions Manual TIME(3) NAME time -- get time of day LIBRARY Standard C Library (libc, -lc) SYNOPSIS #include \u0026lt;time.h\u0026gt; time_t time(time_t *tloc); ... You would use this information if you were writing programs to run on the system.\nHere we can see why the sections are important to know about. There are multiple entries for time. We need to use the sections to differentiate between them.\nRunning man time would not open the page above, because man searches the library in ascending section order, meaning that it actually finds time(1) and shows the pages for the time program, not the time C library call.\nBecause of the potential ambiguity of names if no section number is included, in lots of Linux documentation you'll see the man section number written next to library calls, system calls, programs and so on (things will refer to sed(1) or time(3) for example.\nSection 4: Devices This section deals with the special devices which live in the /dev/* folder. For example, running man 4 random shows:\nRANDOM(4) BSD Kernel Interfaces Manual RANDOM(4) NAME random , urandom -- random data source devices. SYNOPSIS pseudo-device random DESCRIPTION The random device produces uniformly distributed random byte values of potentially high quality. ... Again, we see that section numbers can be important. If you just run man random, you'll see:\nRANDOM(3) BSD Library Functions Manual RANDOM(3) NAME initstate, random, setstate, srandom, srandomdev -- better random num- ber generator; routines for changing generators LIBRARY Standard C Library (libc, -lc) SYNOPSIS #include \u0026lt;stdlib.h\u0026gt; char * initstate(unsigned seed, char *state, size_t size); long random(void); ... Which is the manpage for random(3), which is C library function, not the /dev/random file!\nWe'll see more of these special files later in the book.\nSection 5: File Formats This section details special files in the system. For example, man 5 crontab shows:\nCRONTAB(5) BSD File Formats Manual CRONTAB(5) NAME crontab -- tables for driving cron DESCRIPTION A crontab file contains instructions to the cron(8) daemon of the gen- eral form: ``run this command at this time on this date''. Each user has their own crontab, and commands in any given crontab will be exe- cuted as the user who owns the crontab. Uucp and News will usually have their own crontabs, eliminating the need for explicitly running su(1) as part of a cron command. ... Which describes the crontab file used to define scheduled tasks. Again, this is different to man crontab which would document crontab(1). Similarly, man 5 passwd is going to show something quite different to man passwd.\nYou'll potentially use this section if you are performing system administration.\nSection 6: Games Nothing says it better than man 6 intro itself (this'll not work on a Mac sadly, but try it on another Linux system):\n... DESCRIPTION Section 6 of the manual describes all the games and funny little programs available on the system. ... There are probably a few silly programs available on your system, here you'll find their manuals. For example, man 6 banner on a Mac shows:\nBANNER(6) BSD Games Manual BANNER(6) NAME banner -- print large banner on printer SYNOPSIS banner [-d] [-t] [-w width] message ... DESCRIPTION Banner prints a large, high quality banner on the standard output. If the message is omitted, it prompts for and reads one line of its stan- dard input. ... This section is going to be highly dependent on your operating system!\nSection 7: Miscellaneous This is where you'll find additional assorted documentation. For example, man 7 ascii shows:\nASCII(7) BSD Miscellaneous Information Manual ASCII(7) NAME ascii -- octal, hexadecimal and decimal ASCII character sets DESCRIPTION The octal set: 000 nul 001 soh 002 stx 003 etx 004 eot 005 enq 006 ack 007 bel ... Section 8: System Commands We've actually already seen one of these commands mentioned, in the manpage for crontab(5) it mentions cron(8). Let's see, with man 8 cron:\nCRON(8) BSD System Manager's Manual CRON(8) NAME cron -- daemon to execute scheduled commands (Vixie Cron) SYNOPSIS cron [-s] [-o] [-x debugflag[,...]] These are commands which system administrators would normally run. You might open section eight unexpectedly, for example man chmod will open chmod(1), but man chown will open chown(8), as it is a system command.\nSome distributions might vary for section nine. On my Mac it contains information about the kernel interfaces, a C style guide and some more.\nGetting the Index of Manual Section Manpages are just files on the filesystem, so you can get the index of a section just by looking in the appropriate folder.\nFor example, to index the available system calls, try ls /usr/share/man/man2:\nEV_SET.2 FD_CLR.2 FD_COPY.2 FD_ISSET.2 FD_SET.2 FD_ZERO.2 _exit.2 accept.2 access.2 acct.2 ... This is quick and easy way to see what sort of entries you have on your system. If you want to work out where an entry lives, use the -w flag:\n$ man -w printf /usr/share/man/man1/printf.1 There are other ways to show the index of each section, but they vary a lot from system to system so showing the actual files is probably easier.\nSearching the Manual You can search the manpage titles and summaries with man -k. For example, man -k cpu shows:\ncpuwalk.d(1m) - Measure which CPUs a process runs on. Uses DTrace dispqlen.d(1m) - dispatcher queue length by CPU. Uses DTrace gasm(n), grammar::me::cpu::gasm(n) - ME assembler You can find more advanced options for searching by using your newfound man skills on man itself.\nYou can also use the apropos or whatis commands to search through the manuals. However, for simplicity I suggest just remember man -k!\nIntroducing tl;dr In general for this book I'm trying to avoid suggesting too many non-standard tools which don't come pre-installed on systems. However, this one is just too good to miss!\nLet's say I need to find and replace some text in a file. I know I can do this with the sed command, but have forgotten the syntax. So I run man sed:\nWow, that's a lot of detail! And this is just page one of six!\nNow let's compare this to the output from tldr (which is short for \u0026ldquo;Too Long, Didn't Read\u0026rdquo;). All I need to do is run tldr sed:\nThe first example is exactly what I'm looking for. Now for any more detail than a few basic examples, I'm going to have to go to the manual, but for the basics this is great.\nYou can install the tldr tool with npm install -g tldr. It's open source and community maintained. You will need Node.js installed to install the tool, the instructions are available online.\nI'd recommend tldr as a first-call for checking to see how to use a command.\nThe Online Cheatsheet One final resource which I think is worth sharing is the website www.cheat.sh. This is a fantastic online collection of \u0026lsquo;cheat sheets\u0026rsquo;.\nThese sheets cover almost all of the tools you will encounter, programming languages and more. But the real beauty of the tool is how it integrates into the shell. To see what I mean, just run the following command:\n$ curl cht.sh You will see something like this:\nThe curl command we'll see again and again. It is a tool which lets you download content from the web. If we load the cheat.sh website (or its shortened version, cht.sh) from the shell, we get a text version of the website. We can now look at all sorts of content by following the guide shown.\nThe Cheat.sh site aggregates many data sources - including tldr! This means we can get information on tools without even having to install a tool like tldr locally.\nThis online cheatsheet is a wonderful resource. As well as guides for specific tools, there are entire courses on programming languages. You can even use it to search for the answers to questions, these features are powered by Stack Overflow. For example:\n$ curl cht.sh/\u0026#34;How do I copy a folder in bash?\u0026#34; You'll see something like this:\nNow that can be a real time saver!\nSummary In this chapter we looked at some of the ways we can get help. To quickly summarise:\n The man tool can be used to look at the manual page for a topic The man pages are grouped into sections, we can see them with man man The tldr tool shows a very short description of a tool, which covers the most common use cases only The cht.sh website can be used directly from the shell to get help on tools or even ask specific questions  Footnotes   Weirdly satisfying to run. \u0026#x21a9;\u0026#xfe0e;\n Which it is always fun to try if you get the chance, and a great way to learn more about the fundamentals of the operating system. \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':6,'href':'/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/','title':"Chapter 6 - Interlude - The Renaissance of the Shell",'content':"Chapter 6 - Interlude - The Renaissance of the Shell This is the first of the \u0026ldquo;interludes\u0026rdquo; which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.\nIn this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.\nIs there a Renaissance of the Shell? To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a specific increase in the popularity of keyboard and script operated systems is a challenge.\nFor the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.\nWe'll look at three specific developments in technology:\n Diversity of programming languages Convergence of operating platforms DevOps  Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.\nThe Changing Technology Landscape So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.\nThe Diversity of Programming Languages There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.\nWith the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the \u0026lsquo;citizen coder\u0026rsquo; section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.\nIt is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of \u0026lsquo;general purpose\u0026rsquo; languages, and a larger number of highly specialised languages (and associated platforms).\n\u0026ldquo;C\u0026rdquo;, and later, \u0026ldquo;C++\u0026rdquo; were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.\n\u0026ldquo;Java\u0026rdquo; become the \u0026lsquo;general purpose\u0026rsquo; language of choice for applications which had to run on many systems. \u0026ldquo;Basic\u0026rdquo; and later \u0026ldquo;C#\u0026rdquo; were the standards for Windows platform development. PHP was a staple for web development.\nAlongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).\nOf course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.\nTransition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:\n Python JavaScript Go TypeScript Rust Kotlin Java C++ SQL C#  Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.\nWhy does this matter for the shell? The answer is that for many new languages, developer tooling is not as mature (some might say bloated) as it is for the \u0026lsquo;Workhorse\u0026rsquo; languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.\nFor server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have had to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.\nIn time tooling will likely catch up and provide a \u0026lsquo;friendly\u0026rsquo; interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be extremely efficient when working, and that overly featured IDEs can get in the way and hide complexity.\nThe modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.\nConvergence of Operating Platforms Whilst the variety in programming languages and developer tooling may have increased, in many ways the operating platforms engineers use have become more homogeneous.\nIn the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.\nThe modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.\nMore and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.\nEven Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.\nPerhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.\nThis has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.\nWhilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.\nDevOps Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.\nIn attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.\nRegardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.\nThe intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.\nThe world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which cannot be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build require automation.\nIn practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to program automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).\nThe rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.\nAnd for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.\n"});index.add({'id':7,'href':'/docs/part-2-core-skills/7-thinking-in-pipelines/','title':"Chapter 7 - Thinking in Pipelines",'content':"Chapter 7 - Thinking in Pipelines Understanding the concept of pipelines in the shell, as well as how input and output work for command line programs is critical to be able to use the shell effectively.\nIn this chapter, we'll look at the ways programs handle input and output, then we'll look at how we can chain multiple commands together with pipelines. We'll also look at some really common ways to use pipelines which should hopefully make your life easier!\nWhen you understand these concepts, it will open up a new world in terms of what you can do with in the shell. We'll briefly touch on the \u0026lsquo;The Unix Philosophy\u0026rsquo;, which is a concept which allows us to perform highly complex tasks by composing together small, simple components.\nInput and Output Many of the programs we have seen so far follow a very similar pattern:\nProgram - Output\" width=\"480px\" /\nIn fact, when you get down to the details, there are very few programs which don't do something like this! As a more concrete example, we can look at the sort program - which sorts the input in alphabetic order:\nWe can easily see this in action by just running sort in a shell. Start the sort program, enter some text, then press Ctrl+D. Ctrl+D (which is normally written as ^D is a special control character which means \u0026lsquo;end of transmission\u0026rsquo; - in this case we use it to tell sort we've finished writing text. If you were to use ^C (which is the interrupt command) it would closes the sort program instead).\n$ sort ogs chase cats and cats chase mice Once you've entered the text you want to sort, hit ^D and you'll see the sorted output:\nDogs and cats cats chase chase mice So by default, the sort command is reading input from the keyboard (until we send it a special message saying we're done), then writing the output to the terminal.\nIn fact, sort is using two special files - stdin and stdout - but what does this mean?\nStanding Input, Output and Error Every program has access to three \u0026lsquo;special\u0026rsquo; files, stdin, stdout and stderr:\n stdin is short for \u0026lsquo;standard input\u0026rsquo; - it's where many programs read their input from stdout is short for \u0026lsquo;standard output\u0026rsquo; - it's where many programs write their output to stderr is short for \u0026lsquo;standard error\u0026rsquo; - it's where some programs write error messages to  Why do I say \u0026lsquo;many\u0026rsquo; and \u0026lsquo;some\u0026rsquo;? Well the reason is that while this is convention, it is not adhered to universally. Anyone who writes a program is free to choose how they read input and write output, so some programs might not follow these conventions. In Chapter 29 we'll look at how to write tools which follow these conventions, as well as others which are useful.\nEach of these files has a special number which is shown in grey in the diagram. This is known as the file descriptor and we'll see it later on. Each of these files also has a special location in the system which you can access directly - you can see these files by running ls -al /dev/std*:\n$ ls -al /dev/std* lr-xr-xr-x 1 root wheel 0 Jan 1 1970 /dev/stderr -\u0026gt; fd/2 lr-xr-xr-x 1 root wheel 0 Jan 1 1970 /dev/stdin -\u0026gt; fd/0 lr-xr-xr-x 1 root wheel 0 Jan 1 1970 /dev/stdout -\u0026gt; fd/1 If you are not familiar with ls (the list directory contents command) then check Chapter 2 - Navigating Your System. The first part of the output isn't too important - but we can see we have three files in the special /dev/ (short for device folder). We can also see the associated file descriptors.\nAs an aside - this is a really fundamental thing we'll see again and again in Unix and Linux - almost everything can be represented as a file. This is a core concept and one we'll touch on regularly.\nWhen you are running programs in a shell, the shell attaches your keyboard to the program's standard input1, and attaches the standard output and standard error to the terminal display:\nThis means when we're in a shell, we can type on the keyboard, which goes to the input of the program and then as the program outputs information and errors they show up on the screen.\nWe can already see the beginnings of a pipeline here. There's a clear flow of data from the keyboard, through the stdin file, through the program, then through the output files, then to the display.\nLooking at some real programs in action will hopefully make this clearer!\nA Pipeline in Action Do you remember the cat command? It's the one which writes the contents of a file to the screen. For example:\n$ cat ~/playground/text/simpsons-characters.txt Artie Ziff Kirk Van Houten Timothy Lovejoy Artie Ziff Nick Riviera Seymore Skinner Hank Scorpio Timothy Lovejoy John Frink Cletus Spuckler Ruth Powers Artie Ziff Agnes Skinner Helen Lovejoy We saw in Chapter 4 - Becoming a Clipboard Gymnast that we could pipe the output of this command into the sort command to order it and then into the uniq command to remove duplicates, like this:\n$ cat ~/playground/text/simpsons-characters.txt | sort | uniq Agnes Skinner Artie Ziff Cletus Spuckler Hank Scorpio Helen Lovejoy John Frink Kirk Van Houten Nick Riviera Ruth Powers Seymore Skinner Timothy Lovejoy The pipe operator (which is the vertical pipe symbol or |) has a very specific meaning in the shell - it attaches the stdout of the first program to the stdin of the second. This means we can now visualise the entire pipeline and see exactly what is going on:\nThat's it! If you can follow what is going on here then you have the key information you need to know to understand how pipelines work. The pipe operator just connects the output of one program to the input of another. A pipeline is just a set of connected programs. Easy!\nWe could do the same thing by writing the output of each step as a file, then reading that file with the next step, but that would mean we'd have a lot of intermediate files to clean up (and if we're processing a big file, it also uses a lot of space). Pipelines let us create complex sequences of operations which work well even on very large files.\nNow we'll look at stdin, stdout and stderr in a little more detail. We'll be seeing these special streams a lot as we go through the book. Knowing more about them is really going to help you when working in the shell or with Linux-like systems.\nCommon Patterns - Standard Input Let's have a quick look at some of the common things we might see as sources of inputs for other programs. Each one illustrates an interesting point about how the shell or the standard input stream works.\nThis list is by no means exhaustive, in fact with a bit of tinkering you can make almost anything the input to anything else, but let's check each example.\nThese examples will use some new programs to transform the output - don't worry about the details of them, each will be described as we go through the book!\nThe Shell\nYou might just use code in the shell as input, for example:\n$ echo \u0026quot;I am in the $PWD folder\u0026quot; | sed 's/folder/directory/' I am in the /Users/dwmkerr/repos/github/dwmkerr/effective-shell directory Here we've just used echo to write out message including a variable and then used the sed (stream editor) program to replace the word folder with directory. We'll get a lot of practice with sd as we go through this book!\nFiles\nWe've already seen a few examples of using cat to write a file to stdout.\nA lot of the time we don't need to use cat many programs accept the path of a file as a parameter, meaning we can just tell the program to open the file directly. For example, we could count the number of lines in a file like this:\n$ cat ~/playground/text/simpsons-characters.txt | wc -l 14 Or more simply, like this:\n$ wc -l ~/playground/text/simpsons-characters.txt 14 /Users/dwmkerr/playground/text/simpsons-characters.txt In this case, we've passed the file path as an argument to the wc (word, line, character and byte count) program. But be aware - not all programs use the same convention or parameter names!\nNow here's a cool trick. Type rev \u0026lt; /dev/stdin, then enter some text and hit ^D or ^C when done. You should see something like this:\n$ rev \u0026lt; /dev/stdin Red Rum muR deR What's going on here? Remember we mentioned that stdin is a special stream which represents input and that it lives at /dev/stdin? This little trick uses redirection to redirect the stdin file to the rev (reverse) command.\nThe \u0026lt; operator redirects the standard input of a program to come from the given file. We could also have written cat /dev/stdin | rev. Or just enter rev and type in the input we want to reverse!\nThe Clipboard\nIn Chapter 4 - Becoming a Clipboard Gymnast we saw a trick to remove formatting from text in the clipboard. Here's a similar trick to reverse the contents of the clipboard:\n$ pbpaste | rev | pbcopy This pipeline pastes the contents of the clipboard to stdout, which is piped to rev (reversing the text) and then pipes the output to pbcopy, which copies the results to the clipboard2.\nFiltered Input\nThis is a trick a friend shared with me. He works with data scientists and whenever he shows them this command they love it!\n$ head -100 100GBFile.csv \u0026gt; 100linefile.csv The head (display first lines of a file) command in this case just grabs the first 100 lines of a file and puts it straight into a smaller, more manageable file. We'll see what the \u0026gt; symbol (the redirection symbol) means in the section lower down on Standard Output.\nYou can also use tail in the same way to get the last lines from a file. And if you are a more advanced user, you might use something like this:\n$ grep -C 5 error /var/log/mylogfile.txt | less We'll see all of these commands as we go through the book, but this very cool trick uses the grep (file pattern searcher) command to search for the text error in the file /var/log/mylogfile.txt, shows five lines of context (-C 5), which are the lines before and after the match, then puts the result into your pager! We'll see the pager just below. We'll do a lot of grep-ing as we go through the book so don't worry if this looks a little confusing for now.\nMany More!\nWe've only scratched the surface - almost any program will write to the standard output, meaning it can be the input for any pipeline you can imagine!\nCommon Patterns - Standard Output Now let's look at some of the things we can do with the standard output:\nSome of these outputs are things we've seen before, but let's do a quick revision.\nDisplay\nThis is what we've been doing a lot of so far. When you are working with the shell interactively this makes a lot of sense.\nIf you have jobs which run in the background (or on a timer, such as backup jobs which run nightly), you might not actually have a terminal attached to the program to see the output, in which case you'll likely write to a file.\nWhat about if you have a lot of output? It can be quite inconvenient to have to scroll through the terminal (or impossible, depending on the system you are on). In this case use a pager. A pager is a program which makes it possible to interactively page through output in the shell, scrolling up and down, searching and so on.\nTry this out as an example:\nls /usr/bin /usr/local/bin /usr/sbin | less You'll see something like this:\nThis long list of files would be hard to search through if it was printed directly to the shell, but in the pager we can use the d and u keys to go down and up, or the / and ? keys to search forwards or backwards.\nPiping into your pager is a really useful trick - you can read more about pagers in Chapter 5 - Getting Help.\nFile\nThe shell has a built in operator which will pipe the standard output of a program and write it to a file. It is the \u0026gt; or redirection operator:\n$ echo \u0026quot;Here's some data\u0026quot; \u0026gt; some_file.txt It's as easy as that! Note that this will overwrite anything already in the file.\nAppend\nWhat if you don't want to overwrite a file, but instead just add a new line? The \u0026gt;\u0026gt; or append redirection operator:\n$ echo \u0026quot;Tuesday was good\u0026quot; \u0026gt;\u0026gt; diary.txt $ echo \u0026quot;Wednesday was better!\u0026quot; \u0026gt;\u0026gt; diary.txt $ echo \u0026quot;Thursday suuucks\u0026quot; \u0026gt;\u0026gt; diary.txt $ cat diary.txt Tuesday was good Wednesday was better! Thursday suuucks This example writes each line in turn to the diary.txt file, appending the text to the end of the file (and creating it if it doesn't already exist).\nAppending to a file is extremely useful for circumstances where you might want to build or update a log of events over time.\nPipe\nThis is what we've spent most of this chapter looking at - to simply pipe the standard output to the standard input of another program!\nIn this case, the output of our program becomes the input of the next one in the pipeline.\nCommon Patterns - Standard Error We haven't actually seen stderr in action yet. Let's see how it works.\n$ mkdir ~/playground/new-folder $ mkdir ~/playground/new-folder mkdir: /Users/dwmkerr/playground/new-folder: File exists In the first call to mkdir, the folder is created successfully. In the second call, we get an error. Now let's try and use this output and make it louder - making all of the text uppercase.\nThere are lots of ways to make text uppercase in the shell, let's use the tr (translate characters) program. Here's an example of how it works:\n$ echo 'Be quiet, this is a library!' | tr '[:lower:]' '[:upper:]' BE QUIET, THIS IS A LIBRARY! Now let's use it to shout out our error message:\n$ mkdir ~/playground/new-folder | tr '[:lower:]' '[:upper:]' mkdir: /Users/dwmkerr/playground/new-folder: File exists In this case the output has not been made uppercase. What's going on?\nTo understand, let's quickly review the three streams:\nWhen we are in the shell, the shell automatically writes the stderr stream to the screen. But the shell's pipe operator pipes stdout only - it is not piping our error output. And the mkdir command is writing this error message to stderr.\nThe command we ran before:\nmkdir ~/playground/new-folder | tr '[:lower:]' '[:upper:]' Actually looks like this:\nThe pipe has piped the standard output to the tr program. But there is no standard output - the error message was written to standard error instead. The shell has still written it to the screen for us, but has not piped it to the tr program.\nSo how do we deal with stderr? Here are some common options:\nNow this might be the ah-ha! moment if you have done some shell scripting before - some of these obscure sequences like 2\u0026gt;\u0026amp;1 might look familiar (even if it is just the thing you know you you always have to Google to get right!).\nLet's take a quick look at some of these options.\nTo Standard Output\nIf we want to be able to pipe the error message to another command, we can use another redirection trick - we can redirect stderr to stdout.\nThe characters 2\u0026gt;\u0026amp;1 look really obscure - let's break it down:\n Take the file with descriptor 2 - which is standard error Redirect it with the redirect symbol \u0026gt; - we saw this in the earlier section Redirect it into the file with descriptor (\u0026amp;) 1 - which is standard output  Remember, there are three \u0026lsquo;magic\u0026rsquo; files each process has access to:\n stdin, the standard input, which has the file descriptor 0 stdout, the standard output, which has the file descriptor 1 stderr, the standard error, which has the file descriptor 2  File descriptors are just numbers the operating system uses to keep track of files. When a program opens a \u0026lsquo;normal\u0026rsquo; file, it'll get a new file descriptor. Here's a little example:\npython \u0026lt;\u0026lt;EOF import os for r in range(3): print(os.open(\u0026#39;/dev/random\u0026#39;, os.O_RDONLY)) EOF This code uses redirection (see how useful it is?) to pipe a small Python script into the Python program, which writes the results to stdout. You will probably see the following output:\n3 4 5 It doesn't really matter whether you know Python or not (and there weird looking EOF is a heredoc which we have a whole chapter on later). The script is just a way of showing the file descriptors that the operating system gives me when I try to open three files (each time I open the same file, the magic /dev/random file which just contains random data).\nThe interesting thing is that the descriptors in my program start from 3 and go upwards - that's because 0, 1 and 2 are already in use, for stdin, stdout and stderr!\nSo to make our error message go through the tr command, we can redirect stderr to stdout, which means the error message will go to stdout and then be piped to tr:\n$ mkdir ~/playground/new-folder 2\u0026gt;\u0026amp;1 | tr '[:lower:]' '[:upper:]' MKDIR: /USERS/DWMKERR/PLAYGROUND/NEW-FOLDER: FILE EXISTS Visually, what is happening is this:\nIf you can wrap your head around this, the other options we showed for stderr might start to make a little more sense.\nA nice trick to remember the slightly obscure ampersand \u0026amp; which references a file descriptor - if you were to write this:\ncat some-file-that-might-not-exist 2\u0026gt;1 What would happen is that the shell would write stderr to a new file with the name 1! Why don't we need an ampersand before the \u0026gt; symbol, only for the file descriptor afterwards? This is just because the shell only supports redirecting file descriptors, so an additional ampersand would be superfluous.\nTo a File\nBefore, we redirected to \u0026amp;2, which is \u0026lsquo;the file with descriptor 2. We can also use a similar trick to redirect to any arbitrary file:\nmkdir ~/playground/new-folder 2\u0026gt;./errors.txt This command just redirects all of the errors (remember, 2 is stderr) to a file called ./errors.txt.\nThis is quite a common trick - run the program, but log the errors to a file for later review.\nTo Nowhere\nWhat if we just don't want to see the errors at all? Well there's a special file called /dev/null which we can use for this. When we write to this file, the operating system just discards the input. In fact, it exists for just this kind of purpose!\nmkdir ~/playground/new-folder 2\u0026gt;/dev/null This just redirects all errors to the black hole of /dev/null - we won't see them on the screen or anywhere else. This is a common way to \u0026lsquo;silence\u0026rsquo; errors3 in shell commands.\nNotice how we're starting to see patterns? This is just redirection, the same tricks we saw for stdout, but we're explicitly redirecting stderr (file descriptor 2). If we don't tell the shell what to redirect, it assumes stdout by default.\nSo if we can redirect, can we append too?\nAppend\nYes! Just like we did with stdout, there's nothing stopping us appending to a file:\nmkdir ~/playground/new-folder 2\u0026gt;\u0026gt;./all-errors.log Just like before, we use \u0026gt;\u0026gt; which means append (rather than overwrite or create).\nAll to a File\nThis is a really important subtlety. If you want to write both stdout and stderr to a file, you might try this:\nls /usr/bin /nothing 2\u0026gt;\u0026amp;1 \u0026gt; all-output.txt If you run this command, you'll get stdout written to all-output.txt, but the error message cannot access '/nothing' is written to the screen, not the file. Why is this?\nBash (and most bash-like shells) process redirections from left to right, and when we redirect we duplicate the source. So breaking this down:\n 2\u0026gt;\u0026amp;1 - duplicate file descriptor 2 (stderr) and write it to 1 - which is currently the terminal! \u0026gt; all-output.txt - duplicate file descriptor 1 (stdout) and write it to a file called all-output.txt  To write everything to the file, try do this:\nls /usr/bin /nothing \u0026gt; all-output.txt 2\u0026gt;\u0026amp;1 This will work. Breaking it down:\n Redirect stdout to the file all-output.txt Now redirect stderr to stdout - which by this point has already been redirected to a file  This can be tough to remember so it's worth trying it out4. There are many variations you can play with and we'll see more as we go through the book.\nOne Last Trick - The T Pipe This is a long chapter, but I can't talk about pipelines without briefly mentioning the T pipe. Check out this command:\ncat ~/playground/text/simpsons-characters.txt | sort | tee sorted.txt | uniq | grep \u0026#39;^A\u0026#39; This command sorts the list of Simpsons characters, removes duplicates and filters down to ones which start with the letter A. And it has the tee command in the middle. What does this do?\nWell the tee command is like a T-pipe in plumbing - it lets the stream of data go in two directions! The sorted.txt file contains the sets of characters after the sort operation, but before the unique and filter operation. Visually, it does this:\nAs soon as you visualise a T-pipe it's easy to remember this useful command! You might use it in more complex pipelines or other scenarios to write things to a file which would otherwise go straight to another program or just the display.\nThinking in Pipelines Once you get comfortable with pipelines, a whole world of possibilities open up.\nJust the day before I wrote this chapter, I had to find out how many unique data points were in a data file, which also included empty lines and comments, it took less than a minute to quickly build this:\ncat data.dat | sort | uniq | grep -v \u0026#39;^#\u0026#39; | wc -l I didn't have to find a special program which does exactly what I needed5 - I just incrementally built a pipeline. Each section I added one by one, writing to the screen each time, until I had it working. The thought process was:\n cat data.dat - OK, first I need to write out the file sort - now I can sort it, that'll put all the blank lines together uniq - this'll remove all of those duplicate blank lines, although it still leaves one blank one at the top! grep -v '^#' - this should get rid of all the lines which start with # wc -l - this'll count the number of lines I'm left with  Now there's probably better ways, and this has an oddity which is that if there are blank lines it'll remove all but one of them (although that would be quick to fix), but it gave me my quick and dirty answer in less than a minute.\nOf course, as things get more complex you might want to build scripts, or use a programming language, or other methods, but this Unix Philosophy (which we'll talk about more as we continue) of having lots of small, simple programs which we can chain together can be immensely powerful.\nSummary We'll see pipelines again and again. The standard streams, redirection, pipelines and all of the tricks we've introduced in this chapter are fundamental not only to using the shell effectively, but really understanding how computer programs work.\nDon't be worried if this feels like a lot to take in - we'll see more and more examples in later chapters which will help reinforce these concepts. If you find yourself struggling later you might want to quickly review this chapter, because we introduced a lot!\nIn this chapter we looked at:\n How each program has access to three \u0026lsquo;standard\u0026rsquo; streams - one for input, one for output and one for reporting errors The standard input stream is available as a file at /dev/stdin, is often called stdin in programming languages, and always has the special file descriptor 0 The standard output stream is available as a file at /dev/stdout, is often called stdout in programming languages, and always has the special file descriptor 1 The standard error stream is available as a file at /dev/stderr, is often called stderr in programming languages, and always has the special file descriptor 2 The Ctrl+D sequence means \u0026lsquo;end of transmission\u0026rsquo; - we can use it to signal that we have completed putting our input into stdin\u0026hellip; \u0026hellip;but the Ctrl+C sequence means \u0026lsquo;interrupt\u0026rsquo; and is normally used to force a program to close We can pipe the output of one program to the input of another with the pipe | symbol We can redirect a file to the standard input of a program with the \u0026lt; operator We can redirect the standard output of a program to create or overwrite a file with the \u0026gt; operator We can redirect the standard output of a program to create or append to a file with the \u0026gt;\u0026gt; operator We can redirect the standard error of a program to its standard output with 2\u0026gt;\u0026amp;1 We can redirect the standard error of a program to another file (such as the \u0026lsquo;null\u0026rsquo; file) with 2\u0026gt;/dev/null We can redirect the standard error of a program to create or append to a file, just like with standard output, using the \u0026gt;\u0026gt; operator  We also briefly saw some commands:\n sort sorts text sed can replace content in text tr can replace parts of text wc can count words or lines of text tee takes the input stream and sends it straight to the output, but also to a file (like a T-pipe in plumbing) grep can filter lines  These programs can do a lot more and are workhorses we'll see in more detail through the book.\nThere are a few chapters which are planned to come later which go into detail on some of the concepts we only briefly touched on:\n Writing Good Programs - How to write programs which use stdin, stdout and stderr sensibly The Unix Philosophy - Why we have so many small simple programs which we can pipe together Streams in Detail - How streams like stdin actually work, especially with things like line endings, command sequences like ^D and so on Signals - A little more on Signals (such as ^C and ^D)  When these chapters are published I'll update the links here. If you want to be updated when new chapters are published, you can Join the Mailing Lits on the Homepage.\nFootnotes\n  Technically there is another layer here, which is the tty. You can see this by running tty in the shell. We'll more about this in the Interlude - What is a Shell section. \u0026#x21a9;\u0026#xfe0e;\n Check Chapter 4 - Becoming a Clipboard Gymnast for how to do this on a Linux or Windows machine. \u0026#x21a9;\u0026#xfe0e;\n Although always use tricks like this with caution! If we had a different error, perhaps one we really do want to know about, we would lose the message in this case. \u0026#x21a9;\u0026#xfe0e;\n There is a very detailed explanation of this behaviour at https://linuxnewbieguide.org/21-and-understanding-other-shell-scripts-idioms/. \u0026#x21a9;\u0026#xfe0e;\n With the correct options, sed could likely do this in a single operation, but I'd probably spend a lot longer Googling the right options for it! \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':8,'href':'/docs/part-2-core-skills/8-fly-on-the-command-line/','title':"Chapter 8 - Fly on the Command Line",'content':"Chapter 8 - Fly on the Command Line This is my favourite chapter of the book! The tricks I picked up on rapidly moving around in the command line have saved me an enormous amount of time over the years.\nIn this chapter, we'll look at the ways you can rapidly move your cursor around on the command line, as well as how to easily open up the current command in an editor (which is incredibly useful if you realise you are building a more complex sequence of commands).\nBelow is a quick reference which you can use - we'll see each operation in more detail as we go through the chapter!\n\n Basic Navigation  Go to beginning / end Move backwards / forwards one word Delete a word or undo a mistake Delete the next word Delete to beginning / clear line Delete to end   Searching  Search Backwards / Forwards Run the command found in a search Edit the command found Stop Searching   Editing In-Place Clear the Screen See the History and Execute a Recent Command Pro Tip: All The Keys! Pro Tip: Transposing! The Power of Readline  Basic Navigation Let's assume we have a very simple command we are writing, which is going to write a quote to a text file:\necho \u0026#34;The trouble with writing fiction is that it has to make sense, whereas real life doesn\u0026#39;t. -- Iain M. Banks\u0026#34; \u0026gt;\u0026gt; quote.txt Navigating around long lines of text is a slow process if you are only relying on the arrow keys.\nLet's see how we can quickly move around and manipulate text!\nGo to beginning / end Quickly jump to the beginning or end of the text:\n Ctrl + a - Go to beginning Ctrl + e - Go to end  Move backwards / forwards one word For a little more fine-grained movement, you can jump backwards or forwards one word at a time:\n Alt + b - Go back one word Alt + f - Go forward one word  Delete a word or undo a mistake As this is the first operation we're seeing which changes the text, it is useful to remember how to undo any changes you make!\n Ctrl + w - Delete a word Ctrl + - - Undo most recent change  Delete the next word We've seen how to delete the word on or behind the cursor, now let's see how to delete the next word:\n Alt + d - Delete next word  Remember, just like any edit you can undo these changes with the Ctrl + - command.\nDelete to beginning / clear line In the Bash shell, you can delete all the way to the beginning of the line with Ctrl + u. However - if you are using the Z-Shell this will delete the entire line!\n Ctrl + u - Delete to beginning of line OR delete line  Delete to end You can also delete all of the way to the end of the line.\n Ctrl + k - Delete to end  When you find yourself repeatedly using the arrow or delete keys, refer back to this section to remind yourself of the shortcut - it will save a lot of time in the long run!\nSearching Once you have the basic navigation commands down, the next essential is searching. Let's assume we've run the following three commands:\n$ command1 param1 param2 param3 $ command2 param4 param5 param6 $ command3 param7 param8 param9 You can search backwards or forwards with Ctrl + r and Ctrl + s. This will search in the current line and then iteratively through previous lines:\nPeople often remember this as searching through the history - but remember that it actually searches the current line as well. So this is often the fastest way to move to the desired location in the current line.\nThis is useful for searching in the current command, but can be also used to quickly search backwards and forwards through the command history:\nAs you type, your command history is searched, the most recent commands coming first. Use the arrow keys to edit the command, press enter to execute it, or Ctrl + g to cancel the search.\nI think it's a little easier to see these commands in action with a more realistic example, so here's how they look with the text we used earlier.\nSearch Backwards / Forwards Search backwards or forwards through the current line and also the history:\n Ctrl + r - Search backwards (reverse search) Ctrl + s - Search forwards  Run the command found in a search This one is easy! Just hit Enter: Edit the command found When you have found the command or positioned the cursor where you want it, use the Left or Right arrow keys to stop searching and to go back into the normal editing mode:\nStop Searching Cancel the search and return back to the text as it was before you started with the Ctrl + g command:\nEditing In-Place These tips and tricks are helpful, but if you are working with a really long or complex command, you might find it useful just to jump into your favourite editor. This is one of those tricks that when you know it, you'll wonder how you lived without it!\nUse Ctrl + x , Ctrl + e to edit-in place, opening the current command line in your default editor:\nNow it's important to explain that this is the shell's default editor. This might not be the same as the default editor for your operating system. You can see what the shell is using as its default editor by printing the contents of the EDITOR environment variable. For example, my shell will show this:\n$ echo $EDITOR vim This means vim will be used to edit the command line. Your shell might use emacs or nano as a default editor. Unless you are familiar with vim or emacs, you might not find them particularly user friendly as an editor. You can change your default editor by setting the EDITOR variable. For example, below I set the editor to code (with the -w flag which tells the code program not to return control immediately back to the shell but instead wait until I've finished editing the file):\nNow this works (just about), but I wouldn't recommend using a Graphical Editor like Visual Studio Code for this. The reason is that because the editor runs in a separate window, it is actually easy to lose track of it (or the shell). You pause to take a short break, come back, close the editor and the contents are either lost or written to the shell (and if you see in the example above, the shell actually executed the command, rather than just putting it in the command line ready for me to execute).\nThe other reason to avoid a graphical editor is that if you are using a shell on another user's machine, the editor might not be present (or might be configured differently). In general however, the main reason to avoid a graphical editor is that it moves the context of the command away from where you are in the shell to another place, which can be confusing. If you see the screenshot below, I have two editors open:\nThe top right pane has my git commit command running (which is asking me to write a description of my changes) and the bottom right pane has the command line editor running (where I am testing out the commands for this chapter).\nIn this example, each editor has taken the place of the contents of the shell, so there's no ambiguity about which command I am editing. If I was to open a graphical editor, it would open multiple tabs for this operation and I'd have to track which tab was which.\nIt can be daunting to learn an editor like vim or emacs. Chapter 27 goes into more detail on the terminal based text editors - for now if you are not familiar with these programs I recommend you use the nano editor. Nano is small, simple and shows the shortcuts in a convenient menu at the bottom of the screen:\nIn Chapter 18 we'll see how to make permanent customisations to the shell, configuring things like the default editor.\nClear the Screen Probably the shortcut I use the most is Ctrl + l, which clears the screen without trashing your current command. Here's how it looks:\nThis is very helpful if you have a lot of noise and output on the screen and are ready to start with a fresh command.\nSee the History and Execute a Recent Command Just a few days ago a friend showed me a fantastic trick. If you run the history command, the shell will print the recent history of commands you have entered. But as an added bonus, you can execute any of these commands by entering an exclamation mark and the number next to the command:\nThe number is actually just the line number in the history file. Most shells maintain a history of commands which have been entered (to allow for things like searching through old commands). Where this history file is kept will depend on your shell, configuration and operating system, but in most cases you can find the file by running:\necho $HISTFILE There are many configuration options for the shell history. But the main thing to remember is that you can see recent history with the history command and quickly execute the command at line n by running !n.\nPro Tip: All The Keys! You can use the bindkey command to see a list of all keyboard shortcuts:\n$ bindkeys \u0026quot;^@\u0026quot; set-mark-command \u0026quot;^A\u0026quot; beginning-of-line \u0026quot;^B\u0026quot; backward-char \u0026quot;^D\u0026quot; delete-char-or-list \u0026quot;^E\u0026quot; end-of-line \u0026quot;^F\u0026quot; forward-char \u0026quot;^G\u0026quot; send-break \u0026quot;^H\u0026quot; backward-delete-char \u0026quot;^I\u0026quot; expand-or-complete \u0026quot;^J\u0026quot; accept-line \u0026quot;^K\u0026quot; kill-line \u0026quot;^L\u0026quot; clear-screen ... This is an extremely useful command to use if you forget the specific keyboard shortcuts, or just want to see the shortcuts which are available.\nPro Tip: Transposing! If you've mastered all of the commands here and feel like adding something else to your repertoire, try this:\nThe Alt + t shortcut will transpose the last two words. Use Ctrl + t to transpose the last two letters:\nThese two commands were new to me when I was researching this chapter. I can't see myself ever being able to remember the commands more quickly than just deleting the last two words (Ctrl+w twice!) or characters and re-typing them, but perhaps you'll find them useful!\nThe Power of Readline All of the movement commands you've learned in this chapter apply to:\n Bash zsh The Python REPL The Node.js REPL  And many more! The reason is that all of these programs use the same library under the hood to control reading command line input. This library is called GNU Readline.\nIf you are ever looking to go deeper on this topic then search the web for GNU Readline. You can actually configure lower level details of how all programs which use readline work, with the .inputrc configuration file.\nThis configuration file can be used to configure things like the shortcuts used to move around. All of these shortcuts should be familiar to Emacs users. There is in fact also \u0026lsquo;Vi Mode\u0026rsquo; option for readline, which allows you to use vi commands to work with text. You can enter this mode with set -o vi.\nThere's a great cheat sheet on emacs readline commands at readline.kablamo.org/emacs, which is a very useful reference if you want to dig deeper.\nWe'll also see GNU Readline later on when we talk about writing programs which work well in the shell.\nI Hope that was useful! Being able to rapidly move around the command line will hopefully save you time and make you a more confident user of not just the shell, but many command line programs.\n Footnotes\nGIFs were made with LICEcap.\n"});index.add({'id':9,'href':'/docs/part-2-core-skills/9-job-control/','title':"Chapter 9 - Job Control",'content':"Chapter 9 - Job Control Job control is a feature of most shells which can often be somewhat complicated to work with. However, knowing the basics can help prevent you from getting yourself into a tangle and can from time to time make certain tasks a little easier.\nWhat Is Job Control? Let's start with an example. I am building a simple web page. It has one index.html file, one styles.css file, and one code.js file. The index.html file looks like this:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;My New Project\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;styles.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;code.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!--Snip... --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Opening the file in a browser doesn't quite work, as it won't load the code or the styles. We need a web server to serve styles and code.\nA super-useful one-liner to run a web server on any machine with Python installed is:\npython -m SimpleHTTPServer 3000 In fact, this is so useful that I normally alias this command, so that I can just type serve. We'll see aliases in a later chapter.\nMake sure you have the playground folder downloaded, then run the following commands to open the webpage:\n$ cd ~/playground/websites/simple $ python -m SimpleHTTPServer 3000 For now, if we run this command, then we can open the webpage in a browser, with the styles and code loaded:\nWe can also see that the server has served the HTML, JavaScript, and CSS files:\nAll well and good so far.\nThe Problem Let's say we want to now continue using our shell, maybe to edit the website with a terminal editor like Vim or Emacs, or we want to zip up the site, or just run any shell command1.\nWe have a problem. The python process is still running - it's serving the website. Our shell is essentially useless, until we stop the server. See what happens when I try to edit a file:\nIn the example above, I try to run vi, but nothing is happening. Standard input is not being read by the server and not being interpreted by the shell.\nI have to kill the server by hitting Ctrl+C. This sends a SIGINT signal (which tells the command to stop). We saw signals briefly in Chapter 4 - Becoming a Clipboard Gymnast and we'll see more of them in as we continue. Now I need to clear my screen to get rid of all of the error messages, then start again.\nThis is obviously not optimal. Let's look at some solutions.\nSolution 1: Start the Server in the Background In most shells, you can run a command and instruct the shell to run it in the background. To do this, you end the line with an ampersand. Here's how the example would look in this case:\nBy ending the command with an \u0026amp; ampersand symbol, we instruct the shell to run the command as a background job. This means that our shell is still functional. The shell has also notified us that this command is running as a background job with a specific job number:\n$ python -m SimpleHTTPServer 3000 \u0026amp; [1] 19372 In slightly obtuse language, the shell has informed us that it has started a job in the background, with job number 1 and that this job is currently handling the process with ID 19372.\nThe ampersand solution is a fairly common pattern used in day-to-day work. The process is in the background and our shell is available for us to use as normal, the web server will continue to run in the background.\nSolution 2: Move the Server to the Background Let's say you forgot to start the command in the background. Most likely in this case you'd kill the server with Ctrl+C and then start it again with the \u0026amp; option. However, what if this was a large file download or a task you didn't want to abort?\nIn the example below, we'll move the job to the background:\nThe process is currently in the foreground, so my shell is inactive. Hitting Ctrl+Z sends a \u0026lsquo;suspend\u0026rsquo; signal to the process2, pausing it and moving it to the background.\nLet's dissect this:\n$ python -m SimpleHTTPServer 3000 Serving HTTP on 0.0.0.0 port 3000 ... 127.0.0.1 - - [03/Jun/2019 13:38:45] \u0026#34;GET / HTTP/1.1\u0026#34; 200 - ^Z [1] + 21268 suspended python -m SimpleHTTPServer 3000 The shell echos as I type, so we see ^Z (i.e., the Ctrl+Z chord I entered). The shell responds by moving the process into a background job and suspending it.\nThe key here is that it is suspended. The process is paused. So the web server is no longer serving. If you are following with the sample, reload your browser. The webpage fails to load, as the server process is not able to respond to requests.\nTo continue the job, in the background, we use the bg (\u0026lsquo;background\u0026rsquo;) command, with a job identifier (which always starts with a % symbol - we'll see why soon) to tell the shell to continue the job:\n$ bg %1 [1] + 21268 continued python -m SimpleHTTPServer 3000 The shell lets us know the job is being continued, and if we load the webpage again, the content is shown as expected.\nAs a final check, we run the jobs command to see what jobs the shell is running:\n$ jobs [1] + running python -m SimpleHTTPServer 3000 And there you have it - our server is running as a background job. This is exactly what we would see if we run jobs after starting the server with an \u0026amp; at the end. In fact, using an \u0026amp; is perhaps an easier way to remember how to continue a suspended job:\n$ %1 \u0026amp; [1] + 21268 continued python -m SimpleHTTPServer 3000 In the same way ending a command with \u0026amp; runs it in the background, ending a job identifier with \u0026amp; continues it in the background.\nThere is at least one more way to move a job to the background3, but I have not yet found it useful in any scenarios, and it is overly complex to explain. See the footnote for details if you are interested.\nMoving Background Jobs to the Foreground If you have a job in the background, you can bring it back to the foreground with the fg (\u0026lsquo;foreground\u0026rsquo;) command. Let's show the jobs, with the jobs command:\n$ jobs [1] + running python -m SimpleHTTPServer 3000 Here I have a background job running a server. Any one of the following commands will bring it back to the foreground:\nfg %1 # Explicitly bring Job 1 into the foreground %1 # ...or in shorthand, just enter the job id... fg # ...if not given an id, fg and bg assume the most recent job. Now the job is in the foreground, and you can interact with the process again however you like.\nCleaning Up Jobs You might realise you cannot continue what you are doing because an old job is still running. Here's an example:\nI tried to run my web server, but there was still one running as a background job. The server failed to start because the port is in use.\nTo clean it up, I run the jobs command to list the jobs:\n$ jobs [1] + suspended python -m SimpleHTTPServer 3000 There's my old web server. Note that even though it is suspended, it'll still be blocking the port it is serving on4. The process is paused, but it is still holding onto all of the resources it is using.\nNow that I know the job identifier (%1 in this case), I can kill the job:\n$ kill %1 [1] + 22843 terminated python -m SimpleHTTPServer 3000 This is why job identifiers start with a percentage sign! The kill command I have used is not a special job control command (like bg or fg). It is the normal kill command, which terminates a process. But shells that support job control can normally use a job identifier in place of a process identifier. So rather than working out what the process identifier is that I need to kill, I can just use the job identifier5.\nWhy You Shouldn't Use Jobs Avoid jobs. They are not intuitive to interface with and they suffer from some challenges.\nThe most obvious one is that all jobs write to the same output, meaning you can quickly get garbled output like this:\nThis is what happens when I run a job, which just outputs text every second. It's in the background, but it's printing all over my commands. Even running the jobs command to try and find the job to stop it is difficult.\nInput is even more complex. If a job is running in the background, but requires input, it will be silently suspended. This can cause confusion.\nJobs can be used in scripts but must be done so with caution and could easily confuse a consumer of the script if they leave background jobs hanging around, which cannot be easily cleaned up6.\nHandling errors and exit codes for jobs can be problematic, causing confusion, poor error handling, or overly complex code.\nIf jobs should be avoided, why discuss them at all? Well sometimes you move things into the background by mistake, sometimes it can be useful to quickly shift a download or slow command into the background, and also if you are going to avoid something it's good to know why! And the challenge of managing multiple units of work on a computer has been around for a long, long time, with jobs as one of the tools in the toolkit to deal with the challenge.\nBut given I'd suggest to avoid jobs, let's summarise with the most key takeaways and some alternatives.\nThe Most Key Takeaways If there are two things to take away, they would be:\n If you have started running a command in the foreground, and you don't want to stop it and would rather move it to the background, hit Ctrl+Z. Then Google \u0026ldquo;job control\u0026rdquo;.\n And:\n If you think there is a job running in the background, and it is messing with your screen, type fg to bring it to the front and kill it with Ctrl+C. Repeat as needed!\n In either case, if you need to do something more subtle, you can return to this reference. But the first command should allow you to get your shell back while you work out how to continue the job, and the second should kill a background job that is messing with your screen.\nAlternatives to Jobs If you are using any kind of modern terminal such as iTerm, Terminal or the GNOME Terminal, just open a new tab or split! Much easier.\nThe benefit to this is that each tab gets its own standard input and output, so there's no risk of overwriting. And of course you can hide/reveal/rearrange the tabs however you like.\nThe traditional alternative to a job for an operator who simply wants more than one thing going on at once would be a terminal multiplexer, such as screen or tmux:\nMultiplexers work in a very similar way to a modern graphical terminal - they manage many shell instances. But there are some differences.\nModern terminals, such as iTerm, tend to have more intuitive GUIs and a lot of features. Multiplexers can be stateful - and manage work even when you close the shell (allowing you to \u0026lsquo;re-attach\u0026rsquo; later. We can also run them over SSH sessions to manage complex operations on remote machines. They run a client-server model, meaning many people can work with many multiplexed processes (and they can persist beyond sessions).\nMy personal preference is both - I use a modern terminal and run everything inside it in tmux, which is a very common multiplexer (and in some ways the spiritual successor to screen, an older multiplexer). We'll look at both of these options in later chapters.\nQuick Reference You might find that jobs are useful, or you might find that they are not. Either way, here's a quick reference of some common commands:\n   Command Usage     command \u0026amp; Run the command as a background job.   \u0026lt;Ctrl+Z\u0026gt; Move the current process into a background job, suspended.   jobs List all jobs.   fg %1 Move background job number 1 into the foreground.   bg %1 Continue background job number 1.   kill %1 Terminate job number 1.   wait %1 Block until job number 1 exits.    If you want to find out more about the gory details of jobs, the best place to start is the Bash Manual - Job Control Section, or the \u0026lsquo;Job Control\u0026rsquo; section of your preferred shell's manual. On Bash you can find this by using man bash and searching for the text JOB CONTROL. You can find out more about how to get help in Chapter 5 - Getting Help\n Footnotes   If you are not a heavy shell user, this might seem unlikely. But if you do a lot of work in shells, such as sysadmin, devops, or do your coding from a terminal, this happens all the time! \u0026#x21a9;\u0026#xfe0e;\n Technically, SIGTSTP signal - which is \u0026lsquo;TTY stop\u0026rsquo;. If you have always wondered about the \u0026lsquo;TTY\u0026rsquo; acronym, check the chapter, Interlude: Understanding the Shell. \u0026#x21a9;\u0026#xfe0e;\n The alternative method is to use Ctrl+Y, which will send a delayed interrupt, which will continue to run the process until it tries to read from stdin. At this point, the job is suspended and the control given to the shell. The operator can then use bg or kill or fg to either move to the background, stop the process, or keep in the foreground as preferred. See: https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control \u0026#x21a9;\u0026#xfe0e;\n Another super-useful snippet: lsof -i -P -n | grep 8000 to find any process that has a given port open. Another one for the aliases chapter! \u0026#x21a9;\u0026#xfe0e;\n There are times this is needed. If a job runs many processes - for example, by running a pipeline - the process identifier will change as the command moves from one stage of the pipeline to the next. The job identifier will remain constant. Remember, a job is a shell command, so could run many processes. \u0026#x21a9;\u0026#xfe0e;\n To see how bad this can be, create a script that starts jobs, then run it. Then run the jobs command to see what is running. The output might surprise you! \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':10,'href':'/docs/part-2-core-skills/10-understanding-commands/','title':"Chapter 10 - Understanding Commands",'content':"Chapter 10 - Understanding Commands In this chapter, we'll take a look at the various different types of shell commands that exist and how this can affect your work. Commands are far more subtle than you might think and in this chapter we'll look at some of the nuances of commands and the practical consequences for your work.\nBy the end of this chapter, you might even be able to make sense of the horrifying and perfectly syntactically valid code below:\nwhich $(where $(what $(whence $(whereis who)))) What Are Commands? This is really important to understand! A command in a shell is something you execute. It might take parameters. Generally it'll have a form like this:\ncommand param1 param2 We've already seen many commands during this series:\nls # Show the contents of the current directory cd ~ # Move to the user\u0026#39;s home cat file.txt # Output the contents of \u0026#39;file.txt\u0026#39; to stdout But to be an effective shell user, you must understand that not all commands are created equal. The differences between the types of commands will affect how you use them.\nThe Different Types of Commands There are four types of commands in most shells:\n Executables \u0026ldquo;Built-Ins\u0026rdquo; (which we'll just call builtins from now on) Functions Aliases  Each is different and has its own quirks. Let's quickly dig in and see a bit more.\nExecutables - Programs Executables are just files with the \u0026lsquo;executable\u0026rsquo; bit set1. If I execute the cat command, the shell will search for an executable named cat in my $PATH. If it finds it, it will run the program.\n$ cat file.txt This is a simple text file What is $PATH? $PATH is the standard environment variable used to define where the shell should search for programs. If we temporarily empty this variable, the shell won't find the command:\n$ PATH=\u0026#34;\u0026#34; cat file.txt bash: cat: No such file or directory Normally your $PATH variable will include the standard locations for Linux programs - folders such as /bin, /sbin, /usr/bin and so on2.\nIf you were to print the variable, you'd see a bunch of paths (they are separated by colons; I've put them on separate lines for readability):\n/usr/local/bin /usr/bin /bin /usr/sbin /sbin The shell will start with the earlier locations and move to the later ones. This allows local flavours of tools to be installed for users, which will take precedence over general versions of tools.\nThere will likely be other locations too - you might see Java folders, package manager folders and so on.\nExecutables - Scripts Imagine we create a text file called dog in the local folder that looks like this:\n#!/bin/sh echo \u0026#34;🐶 woof 🐶\u0026#34; This is a shell script (you've heard this before, but we'll see a lot more of these as we go through the book!). We mentioned that executables are any files which have the executable bit set. Let's actually do this, using the chmod (change file modes) command:\n$ ls -l dog -rw-r--r-- 1 dwmkerr staff 32 Oct 8 22:44 dog $ chmod +x dog $ ls -l dog -rwxr-xr-x 1 dwmkerr staff 32 Oct 8 22:44 dog I've used ls -l dog to show the file permissions of dog before and after the chmod +x dog3 command. We can see that there are some new x's in the first section. These are saying that the file is now executable by all users.\nNow that we have made the file executable we can run this just like any other program - as long as we tell the shell to look for programs in the current directory:\n$ PATH=\u0026#34;.\u0026#34; dog 🐶 woof 🐶 By the way - don't do this! Adding the special . directory to the path is generally not a safe or sensible thing to do, this is just a demonstration of how it works. More common would be to run the program by specifying the path to the file, like so:\n$ ./dog 🐶 woof 🐶 Another option would just be to move it to a standard location that the shell already checks for programs:\n$ mv dog /usr/local/bin $ dog 🐶 woof 🐶 Executables don't have to be compiled program code, they can be scripts. If a file starts with #! (the \u0026lsquo;shebang\u0026rsquo;), then the system will try to run the contents of the file with the program specified in the shebang.\nWe will look at shebangs in greater detail in a later chapter. But the key takeaway here is that we can also have executable scripts as commands.\nBuiltins OK, so we've seen executables. What about a command like this?\nlocal V=\u0026#34;hello\u0026#34; echo $V You will not find the local executable anywhere on your system. It is a builtin - a special command built directly into the shell program.\nBuiltins are often highly specific to your shell. They might be used for programming (local for example is used to declare a locally scoped variable), or they might be for very shell-specific features.\nThis is where we need to take note. As soon as you are running a builtin, you are potentially using a feature that is specific to your shell, rather than a program that is shared across the system and can be run by any shell.\nTrying to programmatically execute local as a process will fail - there is no executable with that name; it is purely a shell construct.\nSo how do we know if a command is a builtin? The preferred method is to use the type command:\n$ type local local is a shell builtin The type command (which is itself a builtin!) can tell you the exact type of shell command.\nInterestingly, you might be using more builtins than you think. echo is a program, but most of the time you are not executing it when you are in a shell:\n$ type -a echo echo is a shell builtin echo is /bin/echo By using the -a flag on type to show all commands that match the name, we see that echo is actually both a builtin and a program.\nMany simple programs have builtin versions. The shell can execute them much faster.\nSome commands are a builtin so that they can function in a sensible manner. For example, cd command changes the current directory - if we executed it as a process, it would change only the directory for the cd process itself, not the shell, making it much less useful.\nEcho is builtin because the shell can run much more quickly by not actually running a program if it has its own built in implementation.\nBuiltins will vary from shell to shell, but many shells are \u0026lsquo;Bash-like\u0026rsquo; - meaning they will have a set very similar to the Bash builtins, which you can see here:\nhttps://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html\nAs should be familiar from Chapter 5 - Getting Help, you can get help for builtins:\n$ man source # source is a builtin BUILTIN(1) BSD General Commands Manual BUILTIN(1) NAME builtin, !, %, # ...snip... SYNOPSIS builtin [-options] [args ...] However, the manual will not show information on specific builtins, which is a pain. Your shell might have an option to show more details - for example, in Bash you can use help:\n$ help source source: source filename [arguments] Read and execute commands from FILENAME and return. The pathnames in $PATH are used to find the directory containing FILENAME. If any ARGUMENTS are supplied, they become the positional parameters when FILENAME is executed. But remember: help is a builtin; you might not find it in all shells (you won't find it in zsh, for example). This highlights again the challenges of builtins.\nFunctions You can define your own shell functions. We will see a lot more of this later, but let's show a quick example for now:\n$ restart-shell () { exec -l $SHELL } This snippet creates a function that restarts the shell (quite useful if you are messing with shell configuration files or think you might have irreversibly goofed up your current session).\nWe can execute this function just like any command:\n$ restart-shell And running type will show us that this is a function:\n$ type restart-shell restart-shell is a function restart-shell () { exec -l $SHELL } Functions are one of the most powerful shell constructs we will see; they are extremely useful for building sophisticated logic. We're going to see them in a lot more detail later, but for now it is enough to know that they exist, and can run logic, and are run as commands.\nAliases An alias is just a shortcut. Type in a certain set of characters, and the shell will replace them with the value defined in the alias.\nSome common commands are actually already aliases - for example, in my zsh shell, the ls command is an alias:\n% type -a ls ls is an alias for ls -G ls is /bin/ls I make sure that when I use the ls command, the shell always expands it to ls -G, which colours the output.\nWe can quickly define aliases to save on keystrokes. For example:\n$ alias k=\u0026#39;kubectl\u0026#39; From this point on, I can use the k alias as shorthand for the kubectl command.\nAliases are far less sophisticated than functions. Think of them as keystroke savers and nothing more, and you won't go far wrong.\nThe Key Takeaways So we now hopefully have a greater understanding of the variety of shell commands. Not all commands are executables, not all of the commands we think are executables necessarily are, and some commands might be more sophisticated.\nAs a shell user, the key things to remember are:\n Executables are programs your system can use; your shell just calls out to them. Builtins are very shell-specific and usually control the shell itself Functions are powerful ways to write logic but will normally be shell-specific. Aliases are conveniences for human operators, but only in the context of an interactive shell.  To find out how a command is implemented, just use the type -a command:\n$ type -a cat cat is /bin/cat More than You Need to Know OK, for the masochistic few, you might be wondering about all of the other commands and utilities you may have seen that can tell you about programs and commands:\n what whatis which whence where whereis command type  A lot of these are legacy and should be avoided, but for completeness sake, we'll go through them.\nwhat what reads out special metadata embedded in a program, generally used to identify the version of source code it was built from:\n$ what /bin/ls /bin/ls Copyright (c) 1989, 1993, 1994 PROGRAM:ls PROJECT:file_cmds-272.220.1 There should be almost no circumstance in which you need to use it in your day-to-day work, but you might come across it if you meant to type whatis.\nwhatis whatis searches a local help database for text. This can be useful in tracking down manual pages:\n$ whatis bash bash(1) - GNU Bourne-Again SHell bashbug(1) - report a bug in bash But I can't imagine it will be a regularly used tool by most users.\nwhich which will search your $PATH to see whether an executable can be found. With the -a flag, it will show all results.\n$ which -a vi /usr/local/bin/vi /usr/bin/vi which originated in csh. It remains on many systems for compatibility but in general should be avoided due to potentially odd behaviour4.\nwhence whence was added to the Korn shell. You are unlikely to use it unless you are on systems using ksh. zsh also has this command, but it should be avoided and considered non-standard.\n% whence brew /usr/local/bin/brew where This is a shell builtin that can provide information on commands, similar to type:\n% where ls ls: aliased to ls -G /bin/ls However, type should be preferred, as it is more standard.\nwhereis whereis is available on some systems and generally operates the same as which, searching paths for an executable:\n% whereis ls /bin/ls Again, type should be preferred for compatibility.\ncommand command is defined in the POSIX standard, so should be expected to be present on most modern systems. Without arguments, it simply executes a command. With the -v argument, you get a fairly machine-readable or processable response; with the -V argument, you get a more human readable response:\n% command -v ls alias ls=\u0026#39;ls -G\u0026#39; % command -V ls ls is an alias for ls -G command can be useful in scripts, as we will see in later chapters.\ntype type is part of the Unix standard and will be present in most modern systems. As we've already seen, it will identify the type of command as well as the location for an executable:\n% type -a ls ls is an alias for ls -G ls is /bin/ls This command can also be used to only search for paths:\n% type -p ls ls is /bin/ls Summary\nIn summary, avoid anything that starts with \u0026lsquo;w\u0026rsquo;! These are legacy commands, generally needed only when working on older Unix machines. type or command should be used instead.\n Footnotes\n  We will cover permissions and modes in later chapters. \u0026#x21a9;\u0026#xfe0e;\n Why these names and locations? It's a long story. The best place to start if you are interested is the Filesystem Hierarchy Standard. \u0026#x21a9;\u0026#xfe0e;\n chmod changes the mode of a file; +x means \u0026lsquo;add the executable bit\u0026rsquo;. This tells the operating system the file can be executed. \u0026#x21a9;\u0026#xfe0e;\n Stack Exchange: Why not use “which”? What to use then? \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':11,'href':'/docs/part-2-core-skills/11-what-is-a-shell/','title':"Chapter 11 - Interlude - What is a Shell",'content':"Chapter 11 - Interlude - What is a Shell This is the second of the \u0026ldquo;interludes\u0026rdquo; which end each section of the book. These interludes give flavour, concepts, context and the history of some of the concepts we're dealing with. These interlude are not essential to mastering the skills of the shell, but you might find them interesting.\nIn this interlude we'll actually look at what a shell is, all the way from the highest level, which non-technical readers will be able to comfortably follow, to the low level, which advanced users may find illuminating.\nIntroduction for the Non-Technical Reader It might come as a surprise that many technical computer users (programmers, data scientists, systems administrators etc) spend a lot of time using an interface which looks like it's from the sixties:\nIf you work with technologists, you might have seen them using an interface like this. This kind of simple, text-based interface is called a shell, and it has been a common way to interface with computers ever since the first screens and keyboards were created.\nGiven how much computing has advanced, why would people use such an interface? Just look at how much the Windows operating-system has changed over the last three decades:\n(By Source (WP:NFCC#4), Fair use, https://en.wikipedia.org/w/index.php?curid=58853841)\nWhy would people choose to use such an archaic interface as a shell?\n Typing is fast: A skilled shell user can manipulate a system at dazzling speeds just using a keyboard. Typing commands is generally much faster than exploring through user interfaces with a mouse Shells are programmable: Users will often being programming as they work in a shell, creating scripts to automate time-consuming or repetetive processes Shells are portable: A shell can be used to interface to almost any type of computer, from a mainframe to a Raspberry Pi, in a very similar way.  Not all technical users will use a shell regularly, but there are many who will spend the bulk of their time in such an interface. It is such a crucial skill to be able to operate one effectively that I have been writing this series primarily to show ways to be more efficient with this kind of interface.\nIntroduction for the Technical Reader You may be familiar with the shell, but it can be useful to understand some of the surrounding concepts in detail. How does a shell differ from a terminal? What is a tty? How do shells really work? Hopefully as you read this article you'll discovery something that you didn't know about shells.\nLet's Get Started! To understand what shells, terminals, command-prompts and so on are and how they relate, we need to start with the basics: how a modern computer works!\nA Computer in a Nutshell The diagram below shows a simplified view of a typical computer:\nAlready there's a lot going on.\nYour computer is going to have a CPU1 and memory2, and almost certainly a network adapter3 and display adapter4. Most computers will have at least one hard disk. For home PCs, there'll also likely be a bunch of peripherals, such as a mouse, keyboard, printers, flash drives, webcams and so on.\nThe Operating System The operating system is the piece of software installed on a computer that can interface with the hardware. Without hardware, such as a CPU, memory, a network adapter, a graphics card, disk drives and so on, there's not much that you can do with the computer. The operating system is the primary interface to this hardware. No normal programs will talk to hardware directly - the operating system abstracts this hardware away and provides a software interface to it.\nThe abstraction the operating system provides is essential. Developers don't need to know the specifics of how to work with individual devices from different vendors; the operating system provides a standardised interface to all of this. It also handles various tasks such as making sure the system starts up properly.\nThe operating system is generally broken down into two parts - the kernel and user space:\nLet's look at these in more detail.\nThe Kernel This is the part of the operating system that is responsible for the most sensitive tasks: interfacing with physical devices, managing the resources that are available for users and programs, starting up the various systems that are needed, and so on.\nSoftware running in the kernel has direct access to resources, so is extremely sensitive. The kernel will balance resources between the programs in user space, which we'll look at shortly. If you've ever had to install \u0026lsquo;drivers\u0026rsquo;, these are examples of pieces of software that will run in the kernel - they'll have direct access to a physical device you've installed, and expose it to the rest of the software on the computer.\nWhy \u0026lsquo;kernel\u0026rsquo;? The kernel is the soft, edible part of a nut or seed, which is surrounded by a shell. Below you can see a walnut - the kernel is the soft bit in the middle, and the shell surrounds and protects it. This is a useful metaphor that is used for parts of a computer.\n(By Kkchaudhary11 - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=49069244)\nThe operating system kernel really is the core of the operating system. It's such a sensitive area of the operating system that we actually want to avoid running software in it if possible5. And that is where user space comes in.\nUser Space The vast majority of programs run in \u0026lsquo;user space\u0026rsquo; (also commonly called \u0026lsquo;user land\u0026rsquo;).\nWhen a program starts, the kernel will allocate it a private segment of memory and provide limited access to resources. The program is given access to a library of functions by the operating system, which it can use to access resources such as files, devices and so on. Programs in user space are essentially in sandboxes, where there is a limit to how much damage they can do.\nFor example, a program running in user space can use the standard fopen function, which is provided on almost every operating system as part of the C Standard Library. This allows a program to attempt to open a file. The operating system will make a decision on whether the program is allowed to open the file (based on things such as permissions, where the file is and so on) and then, if it is OK with the call, will give the program access to the file. Under the hood, this \u0026lsquo;user space\u0026rsquo; call translates to a system call in the kernel.\nNow that the key components have been introduced, we can look at the shell. The name should come as no surprise, as it is a wrapper or outer layer to the operating system (which itself contains the sensitive nugget of the kernel).\nThe Shell So what is the shell? The shell is just a general name for any user space program that allows access to resources in the system, via some kind of interface.\nShells come in many different flavours but are generally provided to aid a human operator in accessing the system. This could be interactively, by typing at a terminal, or via scripts, which are files that contain a sequence of commands.\nFor example, to see all of the files in a folder, the human operator could write a program in a language such as C, making system calls to do what they want. But for day-to-day tasks, this would be repetitive. A shell will normally offer us a quick way to do that exact task, without having to manually write a program to do it.\nHere's an example, where a shell is being used to show the \u0026lsquo;png\u0026rsquo; images in the folder I am working in6:\nSo a shell is a user-space program to interface with the computer. But there a few more moving parts than just a shell we are seeing in the image above. There are different types of shells, there are terminal programs, and there are the programs or commands that the shell calls (in the example above, tree is a program). Let's pick these apart.\nHere's a diagram that more accurately shows what is going on:\nWe've introduced a few new things here. There's a user, who is interfacing with a terminal, which is running a shell, which is showing a command prompt. The user has written a command that is calling a program (in this case, the tree program).\nLet's dissect this bit by bit.\nThe Terminal We're not directly interacting with the \u0026lsquo;shell\u0026rsquo; in this diagram. We're actually using a terminal. When a user wants to work with a shell interactively, using a keyboard to provide input and a display to see the output on the screen, the user uses a terminal.\nA terminal is just a program that reads input from the keyboard, passes that input to another program (normally a shell), and displays the results on the screen. A shell program on its own does not do this - it requires a terminal as an interface.\nWhy the word terminal? This makes sense when you look at how people interfaced with computers historically. Input to a computer might be through punch cards, and output would often be via a printer. The Teletype Termimal7 became a common way for users to interface with computers.\n(Photograph by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr, CC BY-SA 2.0 fr, https://commons.wikimedia.org/w/index.php?curid=17821795)\nAt this time, computers were very large, complex, and expensive machines. It was common to have many terminals connected to a single large machine (or \u0026lsquo;mainframe\u0026rsquo;), or a few terminals that people would share. But the terminal itself was just a human interface to the operating system. A more modern terminal would be something like an IBM 3486:\n(By ClickRick - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=6693700)\nThis is a very small computer in its own right but still basically just a dumb screen and keyboard connected by a cable to a larger mainframe computer in another location.\nThis mechanism is still very much the case today. When I want to work with a computer in a data centre, I don't go and find the machine, plug in a keyboard and a display and directly interface to it. I run a terminal program on my computer to provide access to the remote machine. My terminal program allows me to use my keyboard and display to work with a remote machine - all via a secure shell - which is a secured-shell connection over a network.\nSo terminals in many ways are quite simple - they are interfaces. But because they are quite simple programs, we can't do much with them. So normally, the first thing that a terminal program will do is run a shell program - a program that we can use to operate the computer.\nThere's nothing special about terminals - anyone can write a program to operate as a terminal, which is why you will see many different terminals around. Examples are the standard \u0026lsquo;terminal\u0026rsquo; app for MacOS X, the gnome-terminal for Linux, and iTerm2 and Hyper. There's a bunch of screenshots of different setups at the end of the article.\nBack to the Shell Now that we've described the terminal, we can go back and look at the shell in detail.\nThe shell is the program that is going to take input from somewhere and run a series of commands. When the shell is running in a terminal, it is normally taking input interactively from the user. As the user types in commands, the terminal feeds the input to the shell and presents the output of the shell on the screen.\nA shell program can also take input from files; these files will then generally be \u0026lsquo;shell scripts\u0026rsquo;. This might be used to run automated operations, such as cleaning up certain folders when a computer starts.\nShells can write output to files or other locations, and so on. You can run a shell program outside of a terminal - you just won't be able to interface with it using a keyboard or display. And in fact, lots of operations happen in this way: automated scripts, startup tasks, installers and so on.\nSo what else does a shell do? Most of the features are related to helping human operators work with the system more efficiently.\n Quickly enter commands, see the history of commands and quickly restructure commands (see Chapter 8 - Fly on the Command Line) Navigate through the file system, moving from folder to folder (see Chapter 1- Navigating Your System), which makes it easier for an operator to navigate the file system Chain the output of commands together - for example, taking the output of one basic program, such as the tree program we saw, and writing it to a file (see Chapter 7 - Thinking in Pipelines) Offer a programming language, allowing the operator to perform more complicated tasks  And a lot more! In fact, that's what the whole book is about - how to get the most from these powerful programs, particularly for those who use them regularly.\nThe Command Prompt or Command Line The last part of the diagram, which we haven't covered yet, is the command prompt.\nWhen a shell is running in terminal, it knows that a human operator will be interfacing with it. So to make sure that the operator has some kind of visual hint that they have to enter commands, the shell will output some kind of prompt.\nI've included a set of screenshots at the end of the article, just after this section, and you can see how some different command prompts look.\nNote that shells don't have to use command prompts - if you use a shell program to execute a script, there will be no command prompt. Shells only show a prompt when they know they are being used interactively. Many programs which allow a user to operate interactively will show a command prompt.\nShell command prompts can be customised, so they will often look different from machine to machine. Below is an example that shows a lot of technical information. This is from the highly popular oh-my-zsh framework for the \u0026lsquo;Z Shell\u0026rsquo; shell, which is very popular among developers:\n*(Source: https://ohmyz.sh/)\nShell Commands and Different Shells A lot of the \u0026lsquo;commands\u0026rsquo; in a shell, such as cat (which shows the contents of a file), are actually just simple programs, which will interface with the kernel. No matter what shell you use, these commands will behave the same way, because really all you are doing is calling another program.\nSome commands, such as cd (change directory), are built into the shell. Some commands are functions that have been defined, or aliases to other commands (for more details on commands, see Chapter 10 - Understanding Commands). Commands will often differ between shells.\nNot all shells are created equal - anyone can write a shell program, maybe creating a simple interface to the computer or a highly complex one with many features. In fact, a later article in this series will look at the genealogy of the most common shells.\nOn most Unix-like systems, the default shell is a program called bash, which stands for \u0026quot; Bourne Again Shell\u0026rdquo; (the name and history around it will be discussed at length in the later article). But there are many other shells: the C Shell, the Korn Shell, Z Shell and Fish, just to name just a few.\nUsers and administrators can configure what shell they like to use. When a terminal opens, it will immediately start the user's preferred shell program. It is possible to change this. Different users will have different preferences, given that shells offer varying features. This can cause complexity when working with systems, as we cannot always expect every user to have the same shell, or even for the same shell to be set up consistently, as they can be extensively customised.\nLet's review the earlier diagram again:\nWe can see the real internals of what is going on in this \u0026ldquo;Terminal -\u0026gt; Shell -\u0026gt; Program\u0026rdquo; chain in the diagram above quite easily.\nTry the command pstree -psa $$ in a shell8:\nThe first systemd process is the primary process for the OS - it is process number 1, which initialises everything else. The second systemd process is the process that is running the interface for my user. We can ignore these for now; they are internals to how the operating system boots and starts processes.\nWhat is interesting is that we can see a terminal (the gnome terminal), which has started my preferred shell (which is zsh), which is running a command (the program pstree). Here we can see the exact chain as shown in the diagram earlier.\nThat's a Wrap! These are the key technologies and concepts that surround a shell.\nIf you are interested in more technical details of working with shells, then my Effective Shell series goes into these topics in depth. The goal of this series is to help teach techniques that making working with shells more efficient.\nTo close the article, below are some examples of different terminals, shells, command prompts and so on.\nExample: iTerm 2 / tmux / zsh In this example, we have:\n A MacOS operating system iTerm2 as the terminal program tmux running as a \u0026lsquo;terminal multiplexer\u0026rsquo; (see Effective Shell: Terminal Multiplexers) zsh (Z Shell) as the shell program, using \u0026lsquo;oh my zsh\u0026rsquo;, which is easily recognised by the % sign in the command prompt. A customised command line, which shows the user and folder on one line, with only the % symbol below, to leave lots of space for the input commands[^10].  Example: Bash In this example, we have:\n A Linux operating system (Ubuntu 14) The gnome terminal bash as the shell In the second screenshot, the user has \u0026lsquo;root privileges\u0026rsquo;, and to indicate this, bash helpfully changes the default command prompt from a dollar sign to a hash sign  Example: Windows Explorer In this example, we have:\n The Windows 10 operating system No terminal The explorer.exe program showing us a graphical shell  This looks different from previous examples. The program, which shows the familiar Windows interface, explorer.exe, is in fact a shell as well, offering interactive access to the operating system and computer resources. The bulk of the Windows APIs to interact with this interface are in the Shell Library. I also maintain a popular library for building extensions to the graphical Windows shell - sharpshell.\nExample: Windows Command Prompt In this example, we have:\n The Windows 10 operating system The command prompt terminal and shell  In Windows, the terminal and shell are combined into a single cmd.exe program. There's an excellent article on the internals - Microsoft DevBlogs: Windows Command-Line: Inside the Windows Console\nExample: Windows PowerShell In this example, we have:\n The Windows 10 operating system The PowerShell terminal  PowerShell is an improvement on the \u0026lsquo;command prompt\u0026rsquo; program that was originally used in Windows, offering much more functionality for scripting and other modern shell features.\nExample: Windows Subsystem for Linux (WSL) In this example, we have:\n The Windows 10 operating system The Bash.exe program  This screenshot, from MSDN: Frequently Asked Questions about Windows Subsystem for Linux shows Bash running in Windows. This is a relatively new feature at the time of writing, allowing Windows users to use a Linux interface to the PC. This is a feature that may become increasingly valuable, as in general it is challenging to write shell code that can run on Windows and Unix-like systems.\nShare and Discuss If you enjoyed this article, please do share it! Feel free to include suggestions, improvements or corrections in the comments below.\n Useful References\n A simple Linux kernel module, showing how basic kernel programming works in Linux: github.com/dwmkerr/linux-kernel-module How Linux Works - Brian Ward StackExchange: What is the exact difference between a \u0026lsquo;terminal\u0026rsquo;, a \u0026lsquo;shell\u0026rsquo;, a \u0026lsquo;tty\u0026rsquo;, and a console? Microsoft: Inside the Windows Console   Footnotes\n  CPU: central processing unit. This is the chip in the computer that does most of the work (which after many layers of abstraction eventually becomes arithmetic and sending simple instructions to other places). \u0026#x21a9;\u0026#xfe0e;\n Memory is the \u0026lsquo;working space\u0026rsquo; where the state of your system is stored. If you are writing a document, the text lives in memory, until you save it, when it then gets written to a hard drive. Memory is ephemeral - everything is gone when you turn off the power to it. \u0026#x21a9;\u0026#xfe0e;\n This is the part of your computer that knows how to do things like connect to a WiFi network, or has a network socket you might plug a network cable into. \u0026#x21a9;\u0026#xfe0e;\n This is the part of your computer you plug the screen into. \u0026#x21a9;\u0026#xfe0e;\n This is because a mistake in Kernel Mode programs can have disasterous effects. It could access any files, no matter who they belong do, control the hardware, install more software - almost anything. Errors in this code can cause terrible issues (like the infamous Windows \u0026lsquo;blue screen of death\u0026rsquo;), and malicious code in the kernel essentially has full access to not only all your data but also your webcam, network adapter and so on. \u0026#x21a9;\u0026#xfe0e;\n As an aside, if you are curious about the visual style of my setup or customisations that have been made, everything in my setup is available online on my \u0026lsquo;dotfiles\u0026rsquo; repo - github.com/dwmkerr/dotfiles. \u0026#x21a9;\u0026#xfe0e;\n And that's where the \u0026lsquo;TTY\u0026rsquo; acronym you will see sometimes comes from. Enter the ps command, and you'll actually see the TTY interface each process is attached to. This is a topic that will come up later in the series. \u0026#x21a9;\u0026#xfe0e;\n $$ is a Bash internal variable. These will also be covered in a later article in the series. \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':12,'href':'/docs/part-3-manipulating-text-and-streams/12-get-to-grips-with-grep/','title':"Chapter 12 - Get to Grips with Grep",'content':"Chapter 12 - Get to Grips with Grep The grep tool is a real workhorse for shell users - once you've learned how to use it you will find yourself using it again and again. In this chapter we'll see how you can use grep for common tasks, and how to use it in combination with other tools.\nAs with the other tools we'll introduce in this chapter, we'll also look at when grep is the right tool for the job and when we should consider other options.\nWhat is Grep A quick check of the manual page for grep gives an overview:\n$ man grep GREP(1) BSD General Commands Manual GREP(1) NAME grep, egrep, fgrep, zgrep, zegrep, zfgrep -- file pattern searcher SYNOPSIS grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]] [-e pattern] [-f file] [--binary-files=value] [--color[=when]] [--colour[=when]] [--context[=num]] [--label] [--line-buffered] [--null] [pattern] [file ...] DESCRIPTION The grep utility searches any given input files, selecting lines that match one or more patterns. By default, a pattern matches an input line if the regular expression (RE) in the pattern matches the input line without its trailing newline. An empty expression matches every line. Each input line that matches at least one of the patterns is written to the standard output. Wow. Lots of options for this command. And confusingly, lots of alternative forms as well (such as egrep, zgrep and so on).\nMaybe the tldr tool will provide a more concise overview?\n$ tldr grep grep Matches patterns in input text. Supports simple patterns and regular expressions. That is indeed a little more concise. By the way, if you are not familiar with how you can get help on commands, check out Chapter 5 - Getting Help. As the manual pages indicate, grep is used to match patterns in files. More advanced users will most likely know exactly what this means, but a more simple description is just:\n Grep lets you search for text or filter text.\n That's it. You can search in files, but you are not limited to searching in files. And you can search for literal text, such as the word \u0026lsquo;error\u0026rsquo;, or you can search for patterns. Patterns in this case means regular expressions - expressions which allow you to be more specific in how you search (such as looking for a set of 16 numbers in a row, like a credit card number, or any text which looks like an email address). You can also do the opposite - filtering out parts of text.\nWe'll use grep to search through text. Let's get straight into it!\nWhy Grep? Why the odd name? Grep is such a commonly used tool that the name has become a verb amongst technologists (people will often suggest you grep for something in files).\nThe name comes from a command which was used in the original ed text editor - the command:\ng/re/p This command ran on all lines (g, for global), applied a regular expression (re, for regular expression) and then printed (p for print) the results. A colleague of Ken Thompson, one of the early innovators and inventors in the Unix world, needed to edit a large file - a file which was too large to fit in ed. Ken wrote the grep program overnight to allow the file's text to be filtered - and the results passed to the ed editor!\nYou can read more about this story and some of the fascinating history of the early days of Unix in a great interview with Brian Kerninghan from Computerfile1.\nSearching Through Text If you've been working through this book, you've probably entered quite a few commands in the shell. Most shells keep a history of the commands you type. Under the hood, when you use the up and down keys to look through commands you entered earlier, or use the Ctrl-R shortcut to search through earlier commands, your shell is looking through this file. If these tricks are not familiar, check Chapter 9 - Fly on the Command Line.\nThe file which keeps the history can vary from shell to shell. For example, on my system, my history for Bash is in the file ~/.bash_history. Let's look at this file:\ncat ~/.bash_history ... cat ~/.ssh/config ssh bastion.cloudops help echo help cd exit This file will likely be huge. Let's search through it using grep! Here's how we can use the grep command to search for lines which contain the text man:\n grep man ~/.bash_history ... man socket k describe services eventstoredb-http-management man cal gcb refactor/performance/standardise-eventstore vi src/tests/handlers/test_command_handlers.py gco src/handlers/command_handlers.py gcb feat/performance/use-eventstore-writer nvim performance.md man grep  Here I can see all of the commands I have recently entered which have the text man in them. Note that the text which matches is highlighted and shown in bold.\nNow what if you a different shell, or forget where the history file lives? A nice trick here is to use the history command. This command prints out the history, as well as the line number. The history command writes to stdout. If we don't give grep a source file, it will simply search through stdin. Just as we learnt in Chapter 7 - Thinking in Pipelines this means we can just grep the output of the history command!\nHere's how that would work:\n history | grep man ... 9125 man socket 9188 k describe services eventstoredb-http-management 9211 man cal 9341 gcb refactor/performance/standardise-eventstore 9344 vi src/tests/handlers/test_command_handlers.py 9347 gco src/handlers/command_handlers.py 9352 gcb feat/performance/use-eventstore-writer 9355 nvim performance.md 10002 man grep  This is easier to remember! There's one more cool trick - if we just type in the exclamation point symbol followed by any line number shown above, we repeat the command! For example, typing in:\n!9355 Would repeat line 9355 of the history (which is nvim performance.md).\nUsing Patterns Now as you can see from the output above, when we searched through my history, we didn't just find times I executed the man command - we found any line which has the characters man in it. What about if we only wanted to find the lines which start with man?\nTo perform a search like this, we can use a regular expression. Here's how it would work:\n history | grep -E \"[0-9]+ man\" ... 9125 man socket 9211 man cal 10002 man grep  Let's break this down. First, we use the -E flag to tell grep to use Extended Regular Expressions. This allows us to use some clever constructs to search for text. After this, we have the actual expression. This expression is made up of the following components:\n [0-9]+ At least one number - any character in the range zero to nine.  man The literal text written, i.e. two spaces and the letters man.  This is just a little hint of the power of regular expressions. They can be daunting at first, and many people never become comfortable with them, but I would strongly encourage you to start exploring them.\nIf you ever want to see how a regular expression works, try using the website regex101.com. It let's you test out regular expressions and also describes exactly how they work. For example, if I enter the regular expression we just used I'll see this:\nWe're going to see more about regular expressions as we go through the book.\nFinding Problems If there's one command I use a lot, it's this:\ngrep -i err The -i flag makes the search case-insensitive. This makes this a very quick way to scan through a file for any text which matches the letters err - making it a very quick way to find errors in log files.\nYou can try this out by using some of the log files in the logs folder of the playground. Here's how you can try it out:\n grep -i err ~/effective-shell/logs/web-server-logs.txt ... 2020-11-29T12:50:30.594Z: info - Serving file '../../../website/public/docs/part-2-core-skills/7-thinking-in-pipelines/images/diagram-stderr-redirect.png'... 2020-11-29T12:50:31.827Z: error - Unhandled error EACCES trying to read '../../../website/public/svg/calendar.svg', returning a 500 2020-11-29T12:50:31.827Z: error - Unhandled error EACCES trying to read '../../../website/public/svg/calendar.svg', returning a 500 2020-11-29T12:50:31.827Z: error - Unhandled error EACCES trying to read '../../../website/public/svg/calendar.svg', returning a 500 2020-11-29T12:50:31.848Z: error - Unhandled error EACCES trying to read '../../../website/public/svg/edit.svg', returning a 500 2020-11-29T12:50:31.849Z: error - Unhandled error EACCES trying to read '../../../website/public/svg/edit.svg', returning a 500  This is a very useful trick. You could use this technique to search for warnings, problems, specific messages and so on.\nThe ABC of Grep There are three really useful parameters for grep, which I used to struggle to remember, until I realised that they are simple - ABC!\nHere's how they work:\n $ grep host -A 3 ./programs/web-server/web-server.js host: process.env.HOST || 'localhost', port: process.env.PORT || getOptonalEnvInt('PORT', 8080), root: process.env.ROOT || process.cwd(), defaultPage: 'index.html', -- httpServer.listen({ host: config.host, port: config.port }); log.info(`Server running on: ${config.host}:${config.port}`); } main();  A stands for after. In this example we show the three lines after each occurrence of the work host in the web-server.js script. This is a quick way to see how something you search for might be used!\nB stands for before - we can use this to see what comes before a match when we're searching. What can lead to us sending an error in our web server? Let's see:\n $ grep throw -B 5 ./programs/web-server/web-server.js // Helper to return an optional numeric environment variable or the default. function getOptonalEnvInt(name, defaultValue) { const val = process.env[name]; if (!val) return defaultValue; const intVal = parseInt(val, 10); if (isNaN(intVal)) throw new Error(`Unable to parse environment variable named '${name}' with value '${val}' into an integer`);  And finally C, the most useful of them all. C stands for context, and lets you see a number of lines before and after each match. What was I up to the last time I ran the git init command? Let's see!\n $ history | grep -C 5 'git init' 5802 git push --follow-tags \u0026\u0026 git push origin 5803 cd ../java-maven-standard-version-sample 5804 rm -rg .git 5805 rm -rf git 5806 rm -rf .idea 5807 git init -h 5808 git remote add origin git@github.com:dwmkerr/java-maven-standard-version-sample.git 5809 git push origin -u 5810 git push -u origin 5811 git push --set-upstream origin master 5812 git rm --cached tpm  Don't forget that these flags need to be capitalised! These three flags are very useful - knowing how to find context of a match can be a lifesaver when quickly searching through text.\nWorking with Multiple Files What about if you have a bunch of files you want to search? One problem we have at the moment is that everything we search through has been a single file. But if we are searching through multiple files, how can we identify where the matches come from?\nThere's a useful pair of flags for this. -H stands for \u0026lsquo;header\u0026rsquo;, which shows the file name before each match. -n stands for \u0026lsquo;number\u0026rsquo;, which makes sure the line number is shown. Here's how we might use this command:\n $ grep -Hn ERROR ./logs/apm-logs/*.logs ... ./logs/apm-logs/apm02.logs:34893:2020-11-27T12:24:37.429Z ERROR [request] middleware/log_middleware.go:95unauthorized {\"request_id\": \"53a41a98-ba12-454e-aadf-72c97dc40e96\", \"method\": \"POST\", \"URL\": \"/config/v1/agents\", \"content_length\": 27, \"remote_address\": \"127.0.0.1\", \"user-agent\": \"elasticapm-python/5.9.0\", \"response_code\": 401, \"error\": \"unauthorized\"} ./logs/apm-logs/apm02.logs:34906:2020-11-27T12:25:11.415Z ERROR [request] middleware/log_middleware.go:95unauthorized {\"request_id\": \"a49d5546-b8d2-4e50-9dd0-6cbf419a365e\", \"method\": \"POST\", \"URL\": \"/config/v1/agents\", \"content_length\": 27, \"remote_address\": \"127.0.0.1\", \"user-agent\": \"elasticapm-python/5.9.0\", \"response_code\": 401, \"error\": \"unauthorized\"}  Note that in this case we searched through many files - anything which matches the *.logs wildcard. To help us identify in which file the match was found, we used the -Hn flags. The beginning of the lines now start with the path of the file and the line number, for example:\n./logs/apm-logs/apm02.logs:34906 You can take this even further:\n$ grep -R -Hn -i error ./logs Adding the -R or recursive flag tells grep to search recursively in folders if they are included in the search.\nV for Invert As long as your remember that -i is the flag for case insensitive, it makes it a little easier to remember v for invert. This tells grep to exclude lines which match the pattern. This works kind of like a filter.\nHere's how I could look through my log files, excluding any messages with \u0026lsquo;debug\u0026rsquo; in them:\n$ grep -v debug ./logs/web-server.logs Don't forget, you can always pipe a series of grep commands together. Rather than trying to work out a perfect pattern which searches for exactly what you want, you could just pipe a a set of commands together:\n$ grep -i error -R ./logs | grep -i -v memory | grep -i -v 'not found' This set of small, simple, commands is chained together to make a more sophisticated operation:\n First we recursively search for any error text in the ./logs folder Then we exclude anything which matches memory Then we exclude anything which matches not found  This is the essence of the Unix Philosophy - with a small number of simple tools, we can compose a more complex workflow!\nDon't Forget Your Pipelines! We've introduced a very powerful command in this chapter. For familiar uses, grep becomes a verb they use regularly - you grep the output of something, or might be grepping to find something. Remember that grep, just like most of the tools in this section, works on stdin by default. So you can easily grep the output of almost anything!\nHere are a few simple examples just to show you how easy it is to perform more complex tasks with grep.\nps -a | grep vim Show all processes, then filter the list down to only vim processes.\ngrep -Hv -C 3 -R password ./k8s/**/*.yaml | less Search through all of the yaml files in my k8s folder, for the text \u0026lsquo;password\u0026rsquo;, show three lines of context, as well as the file name and number, and put the output in my pager so that it is easy to search through.\nls -al /usr/bin /bin /usr/local/bin | grep zip Search through all of my installed programs for programs which have zip in the name.\nhistory | grep grep | tail -n 10 Show me the last ten grep commands I typed in my shell!\nWe'll see a lot more examples as we go through the book - just remember that grep is alwaays available to search or filter text!\nAlternatives to Grep Grep is a very commonly used tool and has been around for a long time. It can vary a bit from system to system. Over the years a number of alternatives have been developed. Most of these alternatives are either designed to be faster, so that you can search through files much more quickly, or easier so that you don't have to remember too many flags.\nIn general, I would advise against using alternatives - until you genuinely find you are limited by grep. Every alternative is another tool to learn, which might not be present on other systems you use. It is also less likely to be available if you are writing scripts or instructions for others.\nIf you find yourself really struggling with performance - perhaps you often search huge folders of text or if you find yourself regularly struggling to find ways to craft your search patterns, then perhaps you can investigate some of the popular alternatives. But I would suggest that you master the core grep functionality first, before installing other tools.\nIf you do decide you want to add some more text searching tools to your toolkit, I would suggest ripgrep, ag and ack as three potential options. Each of them offer performance improvements and additional functionality.\nSummary Grep is a simple text-based search tool! If you need to find text, or want to filter text, then grep should be your go-to tool.\nHere's a summary of what we've covered:\n grep pattern file searches file for the text pattern the -E flag lets you use regular expressions for more sophisticated searches You can make the search case insensitive with the -i flag Remember the ABC flags - after, before and context, which show lines after, before and around the matches Include the filename and line number with the -Hn flags V for invert! Use the -v flag to invert the search, or filter out matches grep works great in pipelines! Use it to search or filter when working with other commands   Footnotes\n  See the interview at: https://www.youtube.com/watch?v=NTfOnGZUZDk\u0026amp;feature=emb_title \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':13,'href':'/docs/0-introduction/','title':"Introduction",'content':"Introduction This book is for anyone who is interested in computing, and wants to learn more about the exciting, but sometimes daunting world of \u0026ldquo;The Shell\u0026rdquo;!\nThe shell is the basic interface for controlling a computer with just a keyboard. People use it for managing computers, writing software, doing data science, or even writing books like I am doing! Here's what the shell looks like:\nIf you are already thinking \u0026ldquo;no, this looks too geeky for me!\u0026rdquo; then think again, for almost anyone who uses a computer, or is interested in computing, this book will introduce what the shell is, how it works, and how to use it effectively.\nIf you are already an experienced user, this book also introduces many advanced topics, tips and tricks, and ways you can increase your productivity in the shell.\nThe goal of this book is to be a collection of small, contained tutorials on how to use the shell more effectively, you can go through it sequentially or just pick and choose the sections which seem the most interesting.\nIf you are already comfortable with running a shell, know what bash is, and know how to run basic commands like ls and cd, are familiar with terms like command and parameter then you can skip through some of the earlier sections and pick up the chapters which sound most interesting to you.\nAll of the content of this book is designed to be suitable to work with Microsoft Windows, Mac OS and Linux. So no matter what system you are running, you should be able to follow along. We will focus primarily on \u0026lsquo;Linux Like\u0026rsquo; environments, which hopefully will give you the skills which you can apply most widely. For Windows, we'll look into how to tweak your system to be able to run all of the samples.\n"});index.add({'id':14,'href':'/docs/section6/reading-list/','title':"Reading List",'content':""});index.add({'id':15,'href':'/docs/part-1-transitioning-to-the-shell/4-clipboard-gymnastics/examples/formatting/','title':"Formatting",'content':" Formatting   Apples Oranges Pears Apples    "});index.add({'id':16,'href':'/docs/part-2-core-skills/11-what-is-a-shell/hack-on/','title':"Hack On",'content':"Hack On! See those system calls! I mentioned earlier on that if you make a call like fopen, the Kernel is going to provide access to a file. It's quite easy to see this in action. Check the code below:\n#include \u0026lt;stdio.h\u0026gt; void main() { void* handle = fopen(\u0026#34;/tmp/some-file\u0026#34;); fwrite(handle, \u0026#34;some text\u0026#34;); fclose(handle); } If you compile this program, then run XXX you will see the actual calls made to the Kernel. It can be very useful to use this technique to see what is going on with programs under the hood, particularly when diagnosing issues.\nHack On! Ahah! So that's TTY? Consider a command like:\ndocker -it Consider a command like:\nssh user@remote.com my-script no tty Once you understand the concept of shells and terminals in a bit more detail, more obscure messages like this start to make sense.\nIn the first instance, we are telling Docker we are interactive - i.e. we are going to use an interface to send commands. The second parameter, -t says use a TTY - which is short for teletype terminal, old fashioned lingo for the screen.\nTODO TTY picture\nTODO Summary; technical For technical readers, there's quite a lot of terms which get thrown about almost interchangeably; shell, command-line, terminal, tty, command-prompt, CLI and so on. But each of these have a very specific meaning. It's important to understand exactly what each of these terms really means, where they came from, and how these different types of system or concept relate to each other.\nSummary; non-tech A computer in a nutshell.\n \u0026ndash; Could link to other layers of abstractions - such as sandboxes in webpages? \u0026ndash; Could link to other layers of abstraction, such as containers?\n"});index.add({'id':17,'href':'/docs/','title':"Docs",'content':""});index.add({'id':18,'href':'/','title':"Effective Shell",'content':"Effective Shell This book is for anyone who is interested in computing, and wants to learn more about the exciting, but sometimes daunting world of \u0026ldquo;The Shell\u0026rdquo;!\nFor the newcomer, you'll learn what a shell is, how to use it on your system, and then how to become more effective everyday by integrating the shell into your work.\nFor the experienced professional, there are chapters which go into advanced topics and introduce real-world ways to be more effective with your usage.\nTo get started, jump over to the Introduction page from the menu or the left, whichever chapter sounds the most appealing!\nTo setup your computer to follow along with the chapters, check the Getting Started guide.\nIf you would like to get email updates when new chapters are published, please do provide your email below. I won't be using it for anything beyond updates to the book.\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;} /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */  Subscribe for Updates      This book is also open source! The code is on github.com/dwmkerr/effective-shell. Feel free to use the \u0026lsquo;Comments\u0026rsquo; section at the bottom of each page to discuss the content, or even open a pull request to propose changes.\n"});index.add({'id':19,'href':'/docs/part-1-transitioning-to-the-shell/','title':"Part 1 - Transitioning to the Shell",'content':"Part 1 - Transitioning to the Shell These are the key skills which everyone should know. Without them, you might struggle to perform certain tasks at all. Experienced users can probably skip this section, or just review the summary. But if you are new to the shell, this is the best place to start! This section focuses on helping you quickly get up to speed with how to perform the same kind of tasks you might have performed in a GUI (Graphical User Interface) with the shell.\n"});index.add({'id':20,'href':'/docs/part-2-core-skills/','title':"Part 2 - Core Skill",'content':"Part 2 - Core Skill In the first part of this book we look at the shell from the perspective of someone who is familiar with a graphical user interface. We studied how to transition from a GUI to the shell, introducing the \u0026lsquo;shell way\u0026rsquo; of performing tasks which you might have previously performed using a GUI.\nIn this section, we'll look at core shell skills. These skills are fundamental to how the shell works, and fundamental to using it effectively. Even if you are familiar with the concepts in each chapter, I would still recommend skimming these sections to make sure there is nothing you have missed.\nA solid understanding of these core skills will be useful for later sections. So even though this book is designed to be something you can dip and dip out of, in any order you choose, it may be worth focusing on this section before moving to later sections.\n"});index.add({'id':21,'href':'/docs/part-3-manipulating-text-and-streams/','title':"Part 2 - Manipulating Text and Streams",'content':"Part 3 - Manipulating Text and Streams A key part of how Linux and Unix systems work is that almost everything is represented as a text file in the system. Almost everything can be configured with simple text file.\nThis means that you may find yourself regularly manipulating text, searching through text and working with text files. There are a lot of options for how to do this! In fact, there are so many options that it can be a bit overwhelming to know what is the right tool for the job.\nIn this section we'll look at some of the key techniques which can be used to work with text, and demonstrate this with practical examples. In each chapter I'll try to show lots of real world use cases to keep things as applicable to usual tasks as possible.\nHopefully, by the time you have completed this section, you will have a great understanding of the tools available to you and how to apply them to the task at hand.\n"});})();